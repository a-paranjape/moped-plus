{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aff408-aed4-41f1-aded-b79340f0ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,shutil\n",
    "from scipy import linalg\n",
    "import scipy.special as sysp\n",
    "\n",
    "sys.path.append('../code/')\n",
    "from sbi import NeuralRatioEstimator\n",
    "\n",
    "import copy,pickle\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as pltcol\n",
    "import gc\n",
    "\n",
    "# cobaya imports\n",
    "from cobaya.run import run\n",
    "from cobaya.log import LoggedError\n",
    "from getdist.mcsamples import loadMCSamples\n",
    "import getdist.plots as gdplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6ee917-7dff-4549-b634-914c8ae8a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['xtick.top'] = True\n",
    "mpl.rcParams['ytick.right'] = True\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['legend.fontsize'] = 12 # 14\n",
    "mpl.rcParams['legend.labelspacing'] = 0.25\n",
    "FS = 18\n",
    "FS2 = 15\n",
    "FS3 = 13\n",
    "FSL = 22\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 6\n",
    "mpl.rcParams['xtick.minor.size'] = 3\n",
    "mpl.rcParams['ytick.major.size'] = 6\n",
    "mpl.rcParams['ytick.minor.size'] = 3\n",
    "\n",
    "#mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba4f11-79a0-4174-b48d-644d2a4ff6e8",
   "metadata": {},
   "source": [
    "# Example usage of NeuralRatioEstimator\n",
    "### simple NRE using Sequential NN tested on (non-)linear Gaussian problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130a605-fa19-4abf-aa29-be652a4ce4be",
   "metadata": {},
   "source": [
    "## Simulator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56875477-3b1c-4a65-b591-4b352edafe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam = 3\n",
    "ndata = 25\n",
    "\n",
    "File_Stem = 'poly' # 'poly','gaussmix'\n",
    "Plots_Dir = File_Stem + '/plots/'\n",
    "\n",
    "class MyNRE(NeuralRatioEstimator):\n",
    "    def __init__(self,params={}):\n",
    "        NeuralRatioEstimator.__init__(self,params=params)\n",
    "\n",
    "        if self.file_stem[:8] == 'gaussmix':\n",
    "            if (self.nparam % 3) != 0:\n",
    "                raise ValueError(\"param_dim must be multiple of 3\")\n",
    "            self.ncomp = self.nparam // 3\n",
    "        \n",
    "        # data variables and noise\n",
    "        self.xvals = np.linspace(-1.5,3.5,self.ndata)\n",
    "        self.sigma = np.linspace(0.05,0.2,self.ndata)\n",
    "        self.cov_mat = np.diagflat(self.sigma**2)\n",
    "\n",
    "        # prior mean,std\n",
    "        self.prior_mean = np.zeros(self.nparam)\n",
    "        self.prior_std = 6*np.ones(self.nparam)\n",
    "\n",
    "        # # prior bounds\n",
    "        # self.theta_min = -10*np.ones(self.nparam)\n",
    "        # self.theta_max = 10*np.ones(self.nparam)\n",
    "        # self.dtheta = self.theta_max - self.theta_min        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def simulator(self,theta):\n",
    "        out = np.zeros((self.ndata,theta.shape[1]))\n",
    "        if self.file_stem[:4] == 'poly':\n",
    "            ####################\n",
    "            # polynomial\n",
    "            out += np.sum(np.array([np.outer(self.xvals**p,theta[p]) for p in range(self.nparam)]),axis=0)\n",
    "            # for x in range(self.xvals.size):\n",
    "            #     out[x] = np.sum([theta[p]*self.xvals[x]**p for p in range(self.nparam)])\n",
    "            ####################\n",
    "        else:\n",
    "            for c in range(self.ncomp):\n",
    "                amp = theta[c*3]\n",
    "                mu = theta[c*3+1]\n",
    "                mu = np.outer(np.ones(self.ndata),mu)\n",
    "                lnsig2 = theta[c*3+2]\n",
    "                # amp,mu,lnsig2 = theta[c*3:(c+1)*3,:]\n",
    "                out += amp*np.exp(-0.5*(self.xvals-mu.T).T**2/np.exp(lnsig2))\n",
    "\n",
    "        noise = self.rng.multivariate_normal(np.zeros(self.ndata),self.cov_mat,size=out.shape[1]) # shape (out.shape[1],out.shape[0])\n",
    "        out += noise.T\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def prior(self,nsamp):\n",
    "        theta = np.zeros((self.nparam,nsamp))\n",
    "        \n",
    "        for p in range(self.nparam):\n",
    "            theta[p] = self.prior_mean[p] + self.rng.randn(nsamp)*self.prior_std[p]\n",
    "            \n",
    "        # for p in range(self.nparam):\n",
    "        #     theta[p] = self.theta_min[p] + self.rng.rand(nsamp)*self.dtheta[p]\n",
    "        \n",
    "        return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b76ac1-4cf8-4683-a4e4-902734a1ae95",
   "metadata": {},
   "source": [
    "## NRE setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea77ddc-634a-43bf-a4b7-5d6ded8c0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = True\n",
    "\n",
    "NReal = 4\n",
    "\n",
    "Parallel = False\n",
    "NProc = 4\n",
    "\n",
    "L1 = 1 # 1 # number of layers with first activation\n",
    "AType1 = 'tanh' # 'tanh'\n",
    "NNodes1 = 25 # 50\n",
    "L2 = 2 # 1 # number of layers with second activation\n",
    "AType2 = 'tanh' # 'tanh'\n",
    "NNodes2 = 50 # 100\n",
    "L3 = 0 # 1 # number of layers with third activation\n",
    "AType3 = 'lrelu' # 'tanh'\n",
    "NNodes3 = 0 # 20\n",
    "\n",
    "NSamp = 30000 # 640000 # ensure multiple of 1000\n",
    "\n",
    "Standardize = True\n",
    "Weight_Decay = 0.0 # 0.0\n",
    "LReLU_Slope = 1.5e-2 # 1e-2\n",
    "\n",
    "params = {'param_dim':nparam,'data_dim':ndata,'standardize':Standardize,'lrelu_slope':LReLU_Slope,\n",
    "          'Lh':L1+L2+L3,'n_hidden_layer':[NNodes1]*L1+[NNodes2]*L2+[NNodes3]*L3,'hidden_atypes':[AType1]*L1+[AType2]*L2+[AType3]*L3,\n",
    "          'wt_decay':Weight_Decay,'file_stem':File_Stem,'nreal':NReal,'parallel':Parallel,'nproc':NProc}\n",
    "\n",
    "print('Setup...')\n",
    "nre_setup = MyNRE(params=params)\n",
    "Complexity = nre_setup.net[1].calc_N_freeparams()*NSamp//1000\n",
    "del nre_setup\n",
    "if NReal > 1:\n",
    "    for r in range(1,NReal+1):\n",
    "        Path(File_Stem+'/r{0:d}'.format(r)).rmdir()\n",
    "params['file_stem'] = File_Stem + '/C{0:d}'.format(Complexity)\n",
    "print('... setup complete with file stem:',params['file_stem'])\n",
    "    \n",
    "start_time = time()\n",
    "if Train:\n",
    "    nre = MyNRE(params=params)\n",
    "    ValFrac = 0.2\n",
    "    params_train = {'max_epoch':1600, # 16000\n",
    "                    'lrate':3e-4, # 3e-5\n",
    "                    'check_after':100, # 1000\n",
    "                    'mb_count':int(np.sqrt((1-ValFrac)*NSamp)),'val_frac':ValFrac}\n",
    "    nre.train(NSamp,params=params_train)\n",
    "    nre.save()\n",
    "    nre.save_train(params_train)\n",
    "else:\n",
    "    with open(params['file_stem'] + '/params.pkl', 'rb') as f:\n",
    "        params = pickle.load(f)  \n",
    "    nre = MyNRE(params=params)\n",
    "    nre.load()\n",
    "    params_train = nre.load_train()\n",
    "    for r in range(1,NReal+1):\n",
    "        nre.net[r].load_loss_history()\n",
    "    \n",
    "print('params_train:',params_train)\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d249e2-e8b2-48df-8830-6de30acbe434",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min val loss...')\n",
    "plt.yscale('log')\n",
    "for r in range(1,NReal+1):\n",
    "    min_val_loss = nre.net[r].val_loss[nre.net[r].val_loss > 0.0].min()\n",
    "    print('... r{0:d} = {1:.3e}'.format(r,min_val_loss))\n",
    "    plt.plot(nre.net[r].epochs,nre.net[r].training_loss,'k-',lw=0.5)\n",
    "    plt.plot(nre.net[r].epochs,nre.net[r].val_loss,'r-',lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42afaa64-8efe-4fb5-991e-6b2d70c1f436",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721f9b2f-ff7d-4d14-97b9-3186162e1c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "First_Use = True\n",
    "\n",
    "print('Architecture:'+nre.file_stem+' ...')\n",
    "\n",
    "if File_Stem == 'gaussmix':\n",
    "    theta_true = nre.cv([2.0,-1.0,0.5])#,-1.0,1.5,1.0]) \n",
    "else:\n",
    "    theta_true = nre.cv([2.0,-1.5,1.0])#,-0.5,0.0,0.5]) \n",
    "\n",
    "data_file = File_Stem + '/data.txt'\n",
    "if First_Use:\n",
    "    data = nre.simulator(theta_true)\n",
    "    np.savetxt(data_file,data[:,0],fmt='%.6e')\n",
    "else:\n",
    "    data = np.loadtxt(data_file)\n",
    "    data = nre.cv(data)\n",
    "\n",
    "Like_Dir = '../code/likes/'\n",
    "\n",
    "Run_MCMC = First_Use # True\n",
    "Run_NRE = True\n",
    "\n",
    "Max_Samples = 1000000\n",
    "Rminus1_Stop = 0.05 # 0.005\n",
    "Rminus1_CL_Stop = 0.1 # 0.025\n",
    "Rminus1_CL_Level = 0.95 # 95\n",
    "\n",
    "Burn_In = 0\n",
    "Burn_Frac = 0.3 # for later use\n",
    "\n",
    "Latex_List = ['a_{{{0:d}}}'.format(p) for p in range(nre.nparam)]\n",
    "Params_List = ['a{0:d}'.format(p) for p in range(nre.nparam)]\n",
    "\n",
    "info = {}\n",
    "info['params'] = {}\n",
    "info['likelihood'] = {'likelihoods.Chi2Like':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':nre.rv(nre.xvals),'Y':data.T,'cov_mat':nre.cov_mat}}\n",
    "if nre.file_stem[:8] == 'gaussmix':\n",
    "    info['theory'] = {'examplelikes.GaussMixTheory':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':nre.rv(nre.xvals),'ncomp':nre.ncomp}}\n",
    "else:\n",
    "    info['theory'] = {'examplelikes.PolyTheory':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':nre.rv(nre.xvals)}}\n",
    "for p in range(len(Params_List)):\n",
    "    ref = 1.0\n",
    "    info['params'][Params_List[p]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                      'prior':{'dist':'norm','loc':nre.prior_mean[p],'scale':nre.prior_std[p]},\n",
    "                                      'proposal':0.01,'latex':Latex_List[p]}\n",
    "\n",
    "info['sampler'] = {'mcmc':\n",
    "                   {'learn_proposal': True,\n",
    "                    'Rminus1_single_split': 4,\n",
    "                    'measure_speeds': True,\n",
    "                    'max_samples': Max_Samples,\n",
    "                    'max_tries': 1000,\n",
    "                    'Rminus1_stop': Rminus1_Stop,\n",
    "                    'Rminus1_cl_stop': Rminus1_CL_Stop,\n",
    "                    'Rminus1_cl_level': Rminus1_CL_Level,\n",
    "                    'burn_in': Burn_In}}\n",
    "info_output = File_Stem + '/stats/chains/'\n",
    "info['output'] = info_output + 'mcmc'\n",
    "info[\"force\"] = True    \n",
    "\n",
    "info_nre = copy.deepcopy(info)\n",
    "info_nre['likelihood'] = {'likelihoods.NRELike':\n",
    "                         {'python_path':Like_Dir}}\n",
    "info_nre['theory'] = {'likelihoods.NRETheory':\n",
    "                         {'python_path':Like_Dir,\n",
    "                          'nre':nre,'data':data,'keys':Params_List}}\n",
    "info_nre['output'] = info_output+'nre_C{0:d}'.format(Complexity)\n",
    "print('... MCMC setup complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0693af-f87c-40ae-bbfc-081b4b7c9688",
   "metadata": {},
   "source": [
    "### Run chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adda33b-1cda-4f95-8f1d-face6249b3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_MCMC:\n",
    "    start_time = time()\n",
    "    updated_info, sampler = run(info)\n",
    "    nre.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdfbead-6636-43f0-96ae-48bfaaec2cd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if Run_NRE:\n",
    "    start_time = time()\n",
    "    updated_info_nre, sampler_nre = run(info_nre)\n",
    "    nre.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13544c03-7472-4177-964f-13740351ed45",
   "metadata": {},
   "source": [
    "### KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51523e63-5f74-4c6b-a1b3-d6a4c28e8796",
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_sample = loadMCSamples(str(Path(info[\"output\"]).resolve()),settings={'ignore_rows':Burn_Frac})\n",
    "sample = gd_sample.samples.T\n",
    "\n",
    "N_Boot = np.min([1000,int(0.2*sample[0].size)])\n",
    "Ind = gd_sample.random_single_samples_indices(random_state=42,max_samples=N_Boot)\n",
    "N_Boot = Ind.size\n",
    "print('N_Boot: ',N_Boot)\n",
    "\n",
    "print('... extracting stats from subsample')\n",
    "for b in range(N_Boot):\n",
    "    theta_b = nre.cv(sample[:dim,Ind[b]])\n",
    "    lgPostNRE = np.log(nre.predict(data,theta_b)*PRIOR(theta_b))\n",
    "    model_boot[b] = model.forward(mnt.X)[0]\n",
    "    nre.status_bar(b,N_Boot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8ae2a-779f-4cae-a5c4-1f5b6ea91f32",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0ef72-018e-4f4c-8cce-24c0c11e78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Fig = False\n",
    "\n",
    "Show_MCMC = True\n",
    "Show_NRE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf1cf98-a79e-4f53-921a-84586c923c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "n_params = len(nre.prior_mean)\n",
    "dim = 1*n_params\n",
    "dof = ndata - n_params\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "if Show_MCMC:\n",
    "    gd_sample = loadMCSamples(str(Path(info[\"output\"]).resolve()),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample.label = 'MCMC' \n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat = gd_sample.getCovMat().matrix[:dim, :dim]\n",
    "    sample = gd_sample.samples\n",
    "    sample = sample.T\n",
    "    ibest = sample[-2].argmin()\n",
    "    mcmc_best = sample[:dim,ibest]\n",
    "    mcmc_chi2 = sample[-2,ibest]\n",
    "    pval = sysp.gammainc(mcmc_chi2/2,dof/2)\n",
    "    mcmc_sig = np.sqrt(np.diag(mcmc_covmat))\n",
    "    print('MCMC...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_best])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2,dof,mcmc_chi2/dof,pval))\n",
    "\n",
    "if Show_NRE:\n",
    "    gd_sample_nre = loadMCSamples(str(Path(info_nre[\"output\"]).resolve()),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample_nre.label = 'NRE: C{0:d}'.format(Complexity)\n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat_nre = gd_sample_nre.getCovMat().matrix[:dim, :dim]\n",
    "    sample_nre = gd_sample_nre.samples\n",
    "    sample_nre = sample_nre.T\n",
    "    iNRE_Id = sample_nre[-2].argmin()\n",
    "    mcmc_NRE_Id = sample_nre[:dim,iNRE_Id]\n",
    "    mcmc_chi2_nre = sample_nre[-2,iNRE_Id]\n",
    "    pval_nre = sysp.gammainc(mcmc_chi2_nre/2,dof/2)\n",
    "    mcmc_sig_nre = np.sqrt(np.diag(mcmc_covmat_nre))\n",
    "    print('NN...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_NRE_Id])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_nre])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_nre,dof,mcmc_chi2_nre/dof,pval_nre))\n",
    "\n",
    "plot_param_list = Params_List\n",
    "Subplot_Size = 1.6\n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter(subplot_size=Subplot_Size)\n",
    "gdplot.settings.num_plot_contours = 3\n",
    "gdplot.settings.axes_fontsize = FS3\n",
    "gdplot.settings.axes_labelsize = FS2\n",
    "gdplot.settings.title_limit_fontsize = FS3\n",
    "\n",
    "show_list = []\n",
    "fill_list = []\n",
    "col_list = []\n",
    "if Show_MCMC:\n",
    "    show_list.append(gd_sample)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('indigo')\n",
    "if Show_NRE:\n",
    "    show_list.append(gd_sample_nre)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('crimson')\n",
    "gdplot.triangle_plot(show_list, plot_param_list,filled=fill_list,\n",
    "                     contour_colors=col_list,legend_loc='upper right',\n",
    "                     title_limit=0)\n",
    "for par_y in range(dim):\n",
    "    str_y = plot_param_list[par_y]\n",
    "    ax = gdplot.subplots[par_y,par_y]\n",
    "    if Show_MCMC:\n",
    "        ax.axvline(mcmc_best[par_y],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "    if Show_NRE:\n",
    "        ax.axvline(mcmc_NRE_Id[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "    for par_x in range(par_y):\n",
    "        str_x = plot_param_list[par_x]\n",
    "        ax = gdplot.subplots[par_y,par_x]\n",
    "        if Show_MCMC:\n",
    "            ax.scatter([mcmc_best[par_x]],[mcmc_best[par_y]],marker='*',s=50,c='aliceblue')\n",
    "            ax.axvline(mcmc_best[par_x],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_best[par_y],c='indigo',ls='--',lw=1.5,alpha=0.6)\n",
    "        if Show_NRE:\n",
    "            ax.scatter([mcmc_NRE_Id[par_x]],[mcmc_NRE_Id[par_y]],marker='*',s=50,c='peachpuff')\n",
    "            ax.axvline(mcmc_NRE_Id[par_x],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_NRE_Id[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "\n",
    "if Save_Fig:\n",
    "    filename = 'contours_'+File_Stem+'_nre{0:d}.png'.format(NRE_Id)\n",
    "    print('Writing to file: '+Plots_Dir+filename)\n",
    "    gdplot.export(fname=filename,adir=Plots_Dir)\n",
    "\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fad33-7728-4e78-a30f-c288a26d0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "plt.errorbar(nre.xvals,data.T[0],yerr=nre.sigma,c='k',capsize=5,marker='o',ls='none')\n",
    "# plt.plot(nre.xvals,theta_true[0,0] + theta_true[1,0]*nre.xvals,'k-')\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258eb84-776b-4f53-9763-b4d188cf1fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b644f22-5503-44ea-87a4-f20217b6250e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0db68-53cd-4a42-9b4e-ad3f11eae06c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5a7896b-7a32-49a3-8838-40ba0dbae978",
   "metadata": {},
   "source": [
    "# OLD RESULTS USING ANALYTICAL COMPARISON & SINGLE REALISATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1958f792-b91c-4468-aaa0-5af412b661e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c72218-abc9-4266-8371-f6219034468c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e79d4de8-286e-4bb0-9f64-20be08aa22d5",
   "metadata": {},
   "source": [
    "## Simulator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654e7edb-407e-41b4-a0d4-ce5f4e3f895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam = 2\n",
    "ndata = 15\n",
    "\n",
    "Tight_Prior = True\n",
    "\n",
    "File_Stem = 'line' # 'line','line-tight'\n",
    "if Tight_Prior:\n",
    "    File_Stem += '-tight'\n",
    "Plots_Dir = File_Stem + '/plots/'\n",
    "\n",
    "class MyNRE(NeuralRatioEstimator):\n",
    "    def __init__(self,params={}):\n",
    "        NeuralRatioEstimator.__init__(self,params=params)\n",
    "\n",
    "        # data variables and noise\n",
    "        self.xvals = np.linspace(-1,2,ndata)\n",
    "        self.sigma = np.linspace(0.1,0.5,ndata)\n",
    "        self.cov_mat = np.diagflat(self.sigma**2)\n",
    "\n",
    "        # prior mean,std\n",
    "        if Tight_Prior:\n",
    "            self.prior_mean = np.array([1.0,-1.0])\n",
    "            self.prior_std = np.array([5.0,5.0])\n",
    "        else:\n",
    "            self.prior_mean = np.array([0.0,0.0])\n",
    "            self.prior_std = np.array([20.0,20.0])\n",
    "        \n",
    "        # # prior bounds\n",
    "        # if Tight_Prior:\n",
    "        #     self.theta_min = np.array([-4.0,-2.0])\n",
    "        #     self.theta_max = np.array([4.0,2.0])\n",
    "        # else:\n",
    "        #     self.theta_min = np.array([-10.0,-3.0])\n",
    "        #     self.theta_max = np.array([10.0,3.0])\n",
    "        # self.dtheta = self.theta_max - self.theta_min        \n",
    "\n",
    "        return\n",
    "    \n",
    "    def simulator(self,theta):\n",
    "        out = np.zeros((self.xvals.size,theta.shape[1]))\n",
    "        ####################\n",
    "        # straight line\n",
    "        for x in range(self.xvals.size):\n",
    "            out[x] = theta[0] + theta[1]*self.xvals[x]\n",
    "        ####################\n",
    "\n",
    "        noise = self.rng.multivariate_normal(np.zeros(self.xvals.size),self.cov_mat,size=out.shape[1]) # shape (out.shape[1],out.shape[0])\n",
    "        out += noise.T\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def prior(self,nsamp):\n",
    "        theta = np.zeros((2,nsamp))\n",
    "\n",
    "        # for p in range(theta.shape[0]):\n",
    "        #     theta[p] = self.theta_min[p] + self.rng.rand(nsamp)*self.dtheta[p]\n",
    "        \n",
    "        for p in range(theta.shape[0]):\n",
    "            theta[p] = self.prior_mean[p] + self.rng.randn(nsamp)*self.prior_std[p]\n",
    "            \n",
    "        return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd0d24-65d0-4f58-8d79-c1ba337d5530",
   "metadata": {},
   "source": [
    "## Analytical ratio for linear Gaussian problem\n",
    "#### with design matrix $\\mathcal{M}$, data $y$, data covariance $C$, prior inverse covariance $F_{\\rm (p)}$, prior mean $\\theta_{\\rm (p)}$, we have\n",
    "#### $F = \\mathcal{M}^{\\rm T}C^{-1}\\mathcal{M} + F_{\\rm (p)}$\n",
    "#### $\\hat\\theta = F^{-1}\\left(\\mathcal{M}^{\\rm T}C^{-1}y + F_{\\rm (p)}\\theta_{\\rm (p)}\\right)$\n",
    "#### $-2\\ln p(\\theta|x) = (\\theta-\\hat\\theta)^{\\rm T}\\,F\\,(\\theta-\\hat\\theta) - \\ln{\\rm det}F + M\\ln(2\\pi)$\n",
    "#### $-2\\ln p(\\theta) = (\\theta-\\theta_{\\rm (p)})^{\\rm T}\\,F_{\\rm (p)}\\,(\\theta-\\theta_{\\rm (p)}) - \\ln{\\rm det}F_{\\rm (p)} + M\\ln(2\\pi)$\n",
    "#### $2\\ln r(y,\\theta) = 2\\ln\\left[p(\\theta|y)/p(\\theta)\\right] = (\\mathcal{M}\\theta)^{\\rm T}C^{-1}(y-\\mathcal{M}\\theta) + \\left(\\mathcal{M}(\\theta-\\hat\\theta)\\right)^{\\rm T}C^{-1}y - (\\hat\\theta-\\theta_{\\rm (p)})^{\\rm T}F_{\\rm (p)}\\theta_{\\rm (p)} + \\ln\\,{\\rm det}(FF_{\\rm (p)}^{-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d2fc9-ae55-48b8-b8ce-93acdfd10521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_nre(nre,X,theta):\n",
    "    designM = np.ones((nre.ndata,nre.nparam))\n",
    "    for p in range(nre.nparam):\n",
    "        designM[:,p] = nre.xvals**p # monomial basis\n",
    "    F_p = np.diagflat(1/nre.prior_std**2) # prior inv Cov\n",
    "    theta_p = nre.cv(nre.prior_mean) # prior mean\n",
    "    Cinv,detC = nre.svd_inv(nre.cov_mat) #np.diagflat(1/nre.sigma**2) # data inv Cov\n",
    "    F = F_p + np.dot(designM.T,np.dot(Cinv,designM)) # posterior inv Cov\n",
    "    theta_hat = np.dot(F_p,theta_p) # posterior mean\n",
    "    theta_hat += np.dot(designM.T,np.dot(Cinv,X))\n",
    "    theta_hat = np.dot(linalg.inv(F),theta_hat)\n",
    "\n",
    "    Mtheta = np.dot(designM,theta)\n",
    "    Mtheta_hat = np.dot(designM,theta_hat)\n",
    "\n",
    "    lnr = np.dot(Mtheta.T,np.dot(Cinv,X-Mtheta))\n",
    "    lnr += np.dot((Mtheta-Mtheta_hat).T,np.dot(Cinv,X))\n",
    "    lnr -= np.dot((theta_hat-theta_p).T,np.dot(F_p,theta_p))\n",
    "    lnr += np.log(linalg.det(F)) - np.log(linalg.det(F_p))\n",
    "    lnr *= 0.5\n",
    "    ratio = np.exp(lnr)    \n",
    "    return ratio,F,theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d79b25-1541-4234-b959-a72904d03568",
   "metadata": {},
   "source": [
    "## NRE setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976f109c-8b09-44e2-9780-e8705267b888",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = True\n",
    "\n",
    "L1 = 1 # 1 # number of layers with first activation\n",
    "AType1 = 'tanh' # 'tanh'\n",
    "NNodes1 = 100 # 50\n",
    "L2 = 1 # 1 # number of layers with second activation\n",
    "AType2 = 'tanh' # 'tanh'\n",
    "NNodes2 = 200 # 100\n",
    "L3 = 0 # 1 # number of layers with third activation\n",
    "AType3 = 'tanh' # 'tanh'\n",
    "NNodes3 = 0 # 20\n",
    "\n",
    "Standardize = True\n",
    "Weight_Decay = 0.0 # 0.0\n",
    "LReLU_Slope = 1e-2 # 1e-2\n",
    "\n",
    "# expect speed 10k epochs/hr\n",
    "\n",
    "start_time = time()\n",
    "if Train:\n",
    "    params = {'param_dim':nparam,'data_dim':ndata,'standardize':Standardize,'lrelu_slope':LReLU_Slope,\n",
    "              'Lh':L1+L2+L3,'n_hidden_layer':[NNodes1]*L1+[NNodes2]*L2+[NNodes3]*L3,'hidden_atypes':[AType1]*L1+[AType2]*L2+[AType3]*L3,\n",
    "              'wt_decay':Weight_Decay,'file_stem':File_Stem}\n",
    "    \n",
    "    nre = MyNRE(params=params)\n",
    "    NSamp = 320000 # 640000\n",
    "    ValFrac = 0.2\n",
    "    params_train = {'max_epoch':32000 if Tight_Prior else 16000,\n",
    "                    'lrate':2e-5 if Tight_Prior else 3e-5,\n",
    "                    'check_after':1000,#1000,\n",
    "                    'mb_count':int(np.sqrt((1-ValFrac)*NSamp)),'val_frac':ValFrac}\n",
    "    nre.train(NSamp,params=params_train)\n",
    "    nre.save()\n",
    "    nre.save_train(params_train)\n",
    "else:\n",
    "    with open(File_Stem + '/params.pkl', 'rb') as f:\n",
    "        params = pickle.load(f)  \n",
    "    nre = MyNRE(params=params)\n",
    "    nre.load()\n",
    "    params_train = nre.load_train()\n",
    "    nre.net.load_loss_history()\n",
    "    \n",
    "print('params_train:',params_train)\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea7a583-fd3b-43d3-b5c0-174e5fa9183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yscale('log')\n",
    "plt.plot(nre.net.epochs,nre.net.training_loss,'k-')\n",
    "plt.plot(nre.net.epochs,nre.net.val_loss,'r-')\n",
    "plt.show()\n",
    "min_val_loss = nre.net.val_loss[nre.net.val_loss > 0.0].min()\n",
    "print('min val loss = {0:.3e}'.format(min_val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5a49d0-ccbb-47c9-a8fd-3f8c395f4e5b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b5e58-1c3c-4ae1-9692-399d7cfb4415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta_true = np.array([[1.0,-1.0]]).T # y = 1 - x\n",
    "# data = nre.simulator(theta_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe88ade-10ed-4783-a064-f524c99b6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.errorbar(nre.xvals,data.T[0],yerr=nre.sigma,c='k',capsize=5,marker='o',ls='none')\n",
    "plt.plot(nre.xvals,theta_true[0,0] + theta_true[1,0]*nre.xvals,'k-')\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3890a1-2c1c-4bda-9358-aa6d7014b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_test = theta_true.copy()\n",
    "ratio,F,theta_hat = analytical_nre(nre,data,theta_test)\n",
    "Ctheta = linalg.inv(F)\n",
    "print('analytical: {0:.3e}'.format(np.squeeze(ratio)))\n",
    "print('predicted : {0:.3e}'.format(np.squeeze(nre.predict(data,theta_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe157e-0910-4ef7-8b67-a6b8cd5af84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = 125\n",
    "theta_vals = np.zeros((nparam,n_grid))\n",
    "for p in range(nparam):\n",
    "    theta_vals[p] = np.linspace(theta_hat[p,0]-4*np.sqrt(Ctheta[p,p]),theta_hat[p,0]+4*np.sqrt(Ctheta[p,p]),n_grid)\n",
    "like_ana = np.zeros((n_grid,n_grid))\n",
    "like_nre = np.zeros_like(like_ana)\n",
    "mask = np.zeros((like_ana.shape[0],like_ana.shape[1]),dtype=bool)    \n",
    "\n",
    "start_time = time()\n",
    "for ix in range(n_grid):\n",
    "    for iy in range(n_grid):\n",
    "        theta_vec= nre.cv([theta_vals[0,ix],theta_vals[1,iy]])\n",
    "        ratio_this,F_this,theta_hat_this = analytical_nre(nre,data,theta_vec)\n",
    "        like_ana[ix,iy] = np.squeeze(ratio_this)\n",
    "        like_nre[ix,iy] = np.squeeze(nre.predict(data,theta_vec))\n",
    "        mask[ix,iy] = (np.dot((theta_vec-theta_hat).T,np.dot(F,theta_vec-theta_hat)) < 11.8)\n",
    "        nre.status_bar(iy + n_grid*ix,n_grid**2)\n",
    "\n",
    "like_ratio_ratio = like_nre/like_ana\n",
    "\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc37268c-1ba8-47aa-8a17-8981de0983a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Vmin,Vmax = 1e-3,1e3\n",
    "# convention of imshow: origin -> top left corner, x-axis pointing downward, y-axis pointing rightward\n",
    "plt.xlabel(\"$\\\\theta_{{0}}$\")\n",
    "plt.ylabel(\"$\\\\theta_{{1}}$\")\n",
    "im = plt.imshow(like_ratio_ratio.T,norm=pltcol.LogNorm(vmin=Vmin,vmax=Vmax),cmap='seismic',\n",
    "                origin='lower',aspect='auto',extent=[theta_vals[0].min(),theta_vals[0].max(),\n",
    "                                                     theta_vals[1].min(),theta_vals[1].max()])\n",
    "levels = np.sort([1e-3,0.01,0.1])\n",
    "con = plt.contour(like_ana.T,levels=levels*like_ana.max(),colors='lightgray',linewidths=1,\n",
    "                  origin='lower',extent=[theta_vals[0].min(),theta_vals[0].max(),\n",
    "                                         theta_vals[1].min(),theta_vals[1].max()])\n",
    "tobj = plt.clabel(con,colors='blueviolet')\n",
    "clabs_old = []\n",
    "for t in range(len(tobj)):\n",
    "    clabs_old.append(tobj[t].get_text())\n",
    "clabs_old = np.sort(np.unique(clabs_old).astype(float)).astype(str)\n",
    "clabs = {clabs_old[l]:str(levels[l]) for l in range(len(levels))}\n",
    "for t in range(len(tobj)):\n",
    "    tobj[t].set(text=clabs[tobj[t].get_text()])\n",
    "    \n",
    "plt.scatter([theta_true[0]],[theta_true[1]],marker='*',s=100,color='gray')\n",
    "plt.scatter([theta_hat[0]],[theta_hat[1]],marker='*',s=100,color='crimson')\n",
    "# plt.scatter([theta_vals[0].max()],[theta_vals[1].min()],marker='*',s=200,color='k')\n",
    "plt.axvline(theta_true[0],c='lightgray',lw=1.5,ls='--')\n",
    "plt.axhline(theta_true[1],c='lightgray',lw=1.5,ls='--')\n",
    "\n",
    "plt.axvline(theta_hat[0,0]-2*np.sqrt(Ctheta[0,0]),c='k',lw=0.5,ls=':')\n",
    "plt.axvline(theta_hat[0,0]+2*np.sqrt(Ctheta[0,0]),c='k',lw=0.5,ls=':')\n",
    "plt.axhline(theta_hat[1,0]-2*np.sqrt(Ctheta[1,1]),c='k',lw=0.5,ls=':')\n",
    "plt.axhline(theta_hat[1,0]+2*np.sqrt(Ctheta[1,1]),c='k',lw=0.5,ls=':')\n",
    "\n",
    "plt.colorbar(im,label='nre / ana')\n",
    "plt.minorticks_on()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a4a994-9dde-4fd3-9886-7dbd8ed0b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ctheta[0,1]/np.sqrt(Ctheta[0,0]*Ctheta[1,1]),like_ratio_ratio[mask].min()/like_ratio_ratio[mask].max()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dfd1fc53-a8a4-4f09-86c0-d7cf49591712",
   "metadata": {},
   "source": [
    "2.1e-3, 0.11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6f0c7b-69d1-4fbe-b32f-c8c8abb7f3b6",
   "metadata": {},
   "source": [
    "## Network architecture comparison\n",
    "#### Ideas from DSJC discussion 30 Mar 2025:\n",
    "    1. Quality factor: use true MCMC chain rather than grid; then no need for analytical result\n",
    "    2. Does convergence of KL divergence between MCMCs from architectures of increasing complexity help as a stopping criterion? \n",
    "    3. Repeat for low-dimensional non-linear (maybe non-Gaussian) problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa95f4a-c01d-4a74-94ca-8b3fa48917c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# raise Exception # uncomment while training to avoid accidental over-writing\n",
    "\n",
    "print('NRE for setup...')\n",
    "with open(File_Stem + '/params.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)  \n",
    "nre_setup = MyNRE(params=params)\n",
    "nre_setup.load()\n",
    "print('... setup complete\\n')\n",
    "\n",
    "N_data_repeat = 25 #// 5\n",
    "N_theta_repeat = 10 #// 5\n",
    "\n",
    "n_grid = 125\n",
    "\n",
    "Fresh_Start = True\n",
    "\n",
    "archfile = File_Stem + '/archs.pkl'\n",
    "if Fresh_Start:\n",
    "    N_archs_old = 0\n",
    "    archs = {}\n",
    "    archs[0] = {'N1':'10','N2':'20','N3':'0','Ns_str':'1k'}\n",
    "    archs[1] = {'N1':'10','N2':'20','N3':'0','Ns_str':'4k'}\n",
    "    archs[2] = {'N1':'25','N2':'50','N3':'0','Ns_str':'4k'} \n",
    "    archs[3] = {'N1':'25','N2':'50','N3':'0','Ns_str':'8k'}\n",
    "    archs[4] = {'N1':'50','N2':'25','N3':'0','Ns_str':'8k'}\n",
    "    archs[5] = {'N1':'25','N2':'50','N3':'0','Ns_str':'80k'}\n",
    "    archs[6] = {'N1':'50','N2':'100','N3':'0','Ns_str':'80k'} \n",
    "    archs[7] = {'N1':'50','N2':'100','N3':'0','Ns_str':'160k'}\n",
    "    archs[8] = {'N1':'100','N2':'50','N3':'0','Ns_str':'160k'} \n",
    "    archs[9] = {'N1':'50','N2':'100','N3':'0','Ns_str':'320k'} \n",
    "    archs[10] = {'N1':'50','N2':'100','N3':'10','Ns_str':'320k'} # --> prev 17 \n",
    "    archs[11] = {'N1':'50','N2':'100','N3':'20','Ns_str':'640k'} # --> prev 18\n",
    "    archs[12] = {'N1':'100','N2':'100','N3':'0','Ns_str':'160k'} \n",
    "    archs[13] = {'N1':'100','N2':'100','N3':'0','Ns_str':'320k'}\n",
    "    archs[14] = {'N1':'100','N2':'200','N3':'0','Ns_str':'160k'} \n",
    "    archs[15] = {'N1':'100','N2':'200','N3':'0','Ns_str':'320k'}\n",
    "    # ----------------------------------------------------------\n",
    "    # below only for line, not line-tight\n",
    "    # ----------------------------------------------------------\n",
    "    # archs[16] = {'N1':'100','N2':'200','N3':'0','Ns_str':'640k'} # --> prev 14\n",
    "    # archs[17] = {'N1':'200','N2':'200','N3':'0','Ns_str':'160k'} \n",
    "    # archs[18] = {'N1':'200','N2':'200','N3':'0','Ns_str':'320k'} # --> needs retraining for line\n",
    "else:\n",
    "    print('Reading architecture data from:',archfile)\n",
    "    with open(archfile, 'rb') as f:\n",
    "        archs = pickle.load(f)  \n",
    "    N_archs_old = np.max(list(archs.keys())) + 1\n",
    "    # archs[N_archs_old] = {'N1':'50','N2':'100','N3':'20','Ns_str':'640k'} \n",
    "\n",
    "N_archs = np.max(list(archs.keys())) + 1\n",
    "backup_dir = File_Stem+'/backup/shallow/'\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "Nsim = N_theta_repeat*N_data_repeat\n",
    "\n",
    "like_ana = np.zeros((Nsim,n_grid,n_grid))\n",
    "mask = np.zeros((Nsim,n_grid,n_grid),dtype=bool)    \n",
    "data_test = np.zeros((Nsim,ndata,1))\n",
    "theta_test = np.zeros((Nsim,nparam,1))\n",
    "theta_vals = np.zeros((Nsim,nparam,n_grid))\n",
    "\n",
    "print('Storing analytical post-prior ratio...')\n",
    "cnt = 0\n",
    "for t in range(N_theta_repeat):\n",
    "    theta_test_this = theta_true.copy() # nre_setup.prior(1)\n",
    "    for d in range(N_data_repeat):\n",
    "        data_test_this = nre_setup.simulator(theta_test_this)\n",
    "        ratio,F,theta_hat = analytical_nre(nre_setup,data_test_this,theta_test_this)\n",
    "        Ctheta = linalg.inv(F)\n",
    "        theta_test[cnt] = theta_test_this\n",
    "        data_test[cnt] = data_test_this\n",
    "\n",
    "        for p in range(nparam):\n",
    "            theta_vals[cnt,p] = np.linspace(theta_hat[p,0]-4*np.sqrt(Ctheta[p,p]),theta_hat[p,0]+4*np.sqrt(Ctheta[p,p]),n_grid)\n",
    "\n",
    "        for ix in range(n_grid):\n",
    "            for iy in range(n_grid):\n",
    "                theta_vec= nre.cv([theta_vals[cnt,0,ix],theta_vals[cnt,1,iy]])\n",
    "                ratio_this,F_this,theta_hat_this = analytical_nre(nre_setup,data_test_this,theta_vec)\n",
    "                like_ana[cnt,ix,iy] = np.squeeze(ratio_this)\n",
    "                # below is for 2-param, 3-sigma: delta chi2 = 11.8\n",
    "                mask[cnt,ix,iy] = (np.dot((theta_vec-theta_hat).T,np.dot(F,theta_vec-theta_hat)) < 11.8) \n",
    "                # nre_setup.status_bar(iy + n_grid*ix,n_grid**2)\n",
    "        nre_setup.status_bar(cnt,Nsim)\n",
    "        cnt += 1\n",
    "\n",
    "print('')\n",
    "\n",
    "for a in range(N_archs_old,N_archs):\n",
    "    N1 = archs[a]['N1']\n",
    "    N2 = archs[a]['N2']\n",
    "    N3 = archs[a]['N3']\n",
    "    archs[a]['arch_size'] = int(N1) + int(N2) + int(N3)\n",
    "    Ns = archs[a]['Ns_str']\n",
    "    archs[a]['Ns'] = int(Ns[:-1])*1000\n",
    "    complexity = int(Ns[:-1])*archs[a]['arch_size']\n",
    "    archs[a]['complexity'] = complexity\n",
    "    net_dir = '1tanh'+N1+'n_1tanh'+N2\n",
    "    if int(N3) > 0:\n",
    "        net_dir += 'n_1tanh'+N3\n",
    "    net_dir += 'n_train'+Ns+'/'\n",
    "    print('Architecture:'+net_dir+' ...')\n",
    "    files = [f for f in Path().glob(backup_dir+net_dir+'*.*')]\n",
    "    for f in files:\n",
    "        shutil.copy(f,File_Stem)\n",
    "\n",
    "    with open(File_Stem + '/params.pkl', 'rb') as f:\n",
    "        params = pickle.load(f)  \n",
    "    nre = MyNRE(params=params)\n",
    "    nre.load()\n",
    "    params_train = nre.load_train()\n",
    "    print('... params_train:',params_train)\n",
    "    print('... calculating network freedom = N_trainingdata / N_freeparams')\n",
    "    archs[a]['freedom'] = archs[a]['Ns']/nre.net.calc_N_freeparams()\n",
    "    print('... loading loss history')\n",
    "    archs[a]['history'] = nre.net.load_loss_history()\n",
    "    print('... recording minimum validation loss')\n",
    "    valloss = archs[a]['history']['val_loss']\n",
    "    archs[a]['MVL'] = valloss[valloss > 0.0].min()\n",
    "\n",
    "    QF_all = np.zeros(Nsim)\n",
    "    cnt = 0\n",
    "    for t in range(N_theta_repeat):\n",
    "        for d in range(N_data_repeat):\n",
    "            # print('... calculating predicted post-prior ratio')\n",
    "            like_nre = np.zeros((n_grid,n_grid))\n",
    "            for ix in range(n_grid):\n",
    "                for iy in range(n_grid):\n",
    "                    theta_vec = nre.cv([theta_vals[cnt,0,ix],theta_vals[cnt,1,iy]])\n",
    "                    like_nre[ix,iy] = np.squeeze(nre.predict(data_test[cnt],theta_vec))\n",
    "                    # nre.status_bar(iy + n_grid*ix,n_grid**2)\n",
    "            \n",
    "            # print('... recording quality factor')\n",
    "            like_ratio_ratio = like_nre/like_ana[cnt]\n",
    "            QF = like_ratio_ratio[mask[cnt]].min()/like_ratio_ratio[mask[cnt]].max()\n",
    "            QF_all[cnt] = QF\n",
    "            nre.status_bar(cnt,Nsim)\n",
    "            cnt += 1\n",
    "    \n",
    "    # below outside data/theta loop\n",
    "    QFmed = np.median(QF_all)\n",
    "    archs[a]['QF'] = QFmed # QF_all.mean()\n",
    "    archs[a]['QFstd'] = QF_all.std()\n",
    "    archs[a]['QFlo'] = QFmed - np.percentile(QF_all,16) \n",
    "    archs[a]['QFhi'] = np.percentile(QF_all,84) - QFmed\n",
    "    \n",
    "    print('... done\\n')\n",
    "\n",
    "print('Storing architecture data to:',archfile)\n",
    "with open(archfile, 'wb') as f:\n",
    "    pickle.dump(archs,f)  \n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c8cd33-b7be-4cc4-9e89-763793c7de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Fig = True\n",
    "\n",
    "# File_Stem = 'line-tight'\n",
    "# Plots_Dir = File_Stem + '/plots/'\n",
    "archfile = File_Stem + '/archs.pkl'\n",
    "print('Loading architecture data from:',archfile)\n",
    "with open(archfile, 'rb') as f:\n",
    "    archs = pickle.load(f)  \n",
    "\n",
    "N_archs = len(list(archs.keys()))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "gs = gridspec.GridSpec(3,1,height_ratios=[1.5,2,1],hspace=0)\n",
    "\n",
    "ax = []\n",
    "Xmin = 0.5*np.min([archs[n]['complexity'] for n in range(N_archs)])\n",
    "Xmax = 4e5 #2.0*np.max([archs[n]['complexity'] for n in range(N_archs)])\n",
    "for i in range(3):\n",
    "    ax_this = plt.subplot(gs[i])\n",
    "    ax_this.set_xscale('log')\n",
    "    ax_this.set_yscale('log')\n",
    "    ax_this.set_xlim(Xmin,Xmax)\n",
    "    if i < 2:\n",
    "        ax_this.set_xticklabels('')\n",
    "        if i == 0:\n",
    "            ax_this.set_ylim(5e-5,5e-2)\n",
    "            ax_this.set_ylabel(\"min($\\\\mathcal{{L}}_{{\\\\rm val}}$)\")\n",
    "        else:\n",
    "            ax_this.set_ylim(3e-4,1)\n",
    "            ax_this.set_ylabel(\"$\\\\mathcal{{Q}}$\")\n",
    "    else:\n",
    "        ax_this.set_xlabel('$\\\\mathcal{{C}}$') \n",
    "        ax_this.set_ylabel('$\\\\mathcal{{F}}$')\n",
    "        ax_this.set_ylim(1,3e2)\n",
    "    ax_this.minorticks_on()\n",
    "    ax.append(ax_this)\n",
    "        \n",
    "for a in range(N_archs):\n",
    "    if int(archs[a]['N3']) == 0:\n",
    "        marker = 'o' if int(archs[a]['N1']) < int(archs[a]['N2']) else 's'\n",
    "        color = 'crimson' if int(archs[a]['N1']) < int(archs[a]['N2']) else 'indigo'\n",
    "    else:\n",
    "        marker = '^'\n",
    "        color = 'forestgreen'\n",
    "    ax[0].scatter([archs[a]['complexity']],[archs[a]['MVL']],marker=marker,c=color)\n",
    "    ax[1].errorbar([archs[a]['complexity']],[archs[a]['QF']],yerr=[[archs[a]['QFlo']],[archs[a]['QFhi']]],\n",
    "                   marker=marker,c=color,capsize=5)\n",
    "    ax[2].scatter([archs[a]['complexity']],[archs[a]['freedom']],marker=marker,c=color)\n",
    "\n",
    "if Save_Fig:\n",
    "    filename = 'archs.png'\n",
    "    print('Writing to file: '+Plots_Dir+filename)\n",
    "    plt.savefig(Plots_Dir+filename,bbox_inches='tight')\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec592f67-3034-43e4-8142-3aa399b6089b",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54441b-096d-40c1-a1e0-0ff309ea3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRE_Id = 18 # best 11,16 for line and 9,10,11,15 for line-tight\n",
    "First_Use = False\n",
    "\n",
    "backup_dir = File_Stem+'/backup/shallow/'\n",
    "\n",
    "archfile = File_Stem + '/archs.pkl'\n",
    "print('Loading architecture data from:',archfile)\n",
    "with open(archfile, 'rb') as f:\n",
    "    archs = pickle.load(f)  \n",
    "    \n",
    "N1 = archs[NRE_Id]['N1']\n",
    "N2 = archs[NRE_Id]['N2']\n",
    "N3 = archs[NRE_Id]['N3']\n",
    "Ns = archs[NRE_Id]['Ns_str']\n",
    "complexity = archs[NRE_Id]['complexity']\n",
    "freedom = archs[NRE_Id]['freedom']\n",
    "\n",
    "net_dir = '1tanh'+N1+'n_1tanh'+N2\n",
    "if int(N3) > 0:\n",
    "    net_dir += 'n_1tanh'+N3 \n",
    "net_dir += 'n_train'+Ns+'/'\n",
    "\n",
    "print('Architecture:'+net_dir+' ...')\n",
    "files = [f for f in Path().glob(backup_dir+net_dir+'*.*')]\n",
    "for f in files:\n",
    "    shutil.copy(f,File_Stem)\n",
    "with open(File_Stem + '/params.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)  \n",
    "\n",
    "nre = MyNRE(params=params)\n",
    "nre.load()\n",
    "params_train = nre.load_train()\n",
    "print('... params_train:',params_train)\n",
    "\n",
    "\n",
    "theta_true = nre.cv([1.0,-1.0]) # y = 1 - x\n",
    "data_file = File_Stem + '/data.txt'\n",
    "if First_Use:\n",
    "    data = nre.simulator(theta_true)\n",
    "    np.savetxt(data_file,data[:,0],fmt='%.6e')\n",
    "else:\n",
    "    data = np.loadtxt(data_file)\n",
    "    data = nre.cv(data)\n",
    "\n",
    "Like_Dir = '../code/likes/'\n",
    "\n",
    "Run_MCMC = False\n",
    "Run_NRE = True\n",
    "\n",
    "Max_Samples = 1000000\n",
    "Rminus1_Stop = 0.005\n",
    "Rminus1_CL_Stop = 0.025 # 0.05\n",
    "Rminus1_CL_Level = 0.95 # 95\n",
    "\n",
    "Burn_In = 0\n",
    "\n",
    "Latex_List = ['a_{0}','a_{1}']\n",
    "Params_List = ['a0','a1']\n",
    "\n",
    "info = {}\n",
    "info['params'] = {}\n",
    "info['likelihood'] = {'likelihoods.Chi2Like':\n",
    "                      {'python_path':Like_Dir,\n",
    "                       'X':nre.rv(nre.xvals),'Y':data.T,'cov_mat':nre.cov_mat}}\n",
    "info['theory'] = {'examplelikes.LineTheory':\n",
    "                  {'python_path':Like_Dir,\n",
    "                   'X':nre.rv(nre.xvals)}}\n",
    "for p in range(len(Params_List)):\n",
    "    ref = 1.0\n",
    "    info['params'][Params_List[p]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                      'prior':{'dist':'norm','loc':nre.prior_mean[p],'scale':nre.prior_std[p]},\n",
    "                                      'proposal':0.01,'latex':Latex_List[p]}\n",
    "\n",
    "info['sampler'] = {'mcmc':\n",
    "                   {'learn_proposal': True,\n",
    "                    'Rminus1_single_split': 4,\n",
    "                    'measure_speeds': True,\n",
    "                    'max_samples': Max_Samples,\n",
    "                    'max_tries': 1000,\n",
    "                    'Rminus1_stop': Rminus1_Stop,\n",
    "                    'Rminus1_cl_stop': Rminus1_CL_Stop,\n",
    "                    'Rminus1_cl_level': Rminus1_CL_Level,\n",
    "                    'burn_in': Burn_In}}\n",
    "info_output = File_Stem + '/stats/chains/'\n",
    "info['output'] = info_output + 'mcmc'\n",
    "info[\"force\"] = True    \n",
    "\n",
    "info_nre = copy.deepcopy(info)\n",
    "info_nre['likelihood'] = {'likelihoods.NRELike':\n",
    "                         {'python_path':Like_Dir}}\n",
    "info_nre['theory'] = {'likelihoods.NRETheory':\n",
    "                         {'python_path':Like_Dir,\n",
    "                          'nre':nre,'data':data,'keys':Params_List}}\n",
    "info_nre['output'] = info_output+'nre{0:d}'.format(NRE_Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d25c05-3e29-466c-b63a-a6c128b5e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_MCMC:\n",
    "    start_time = time()\n",
    "    updated_info, sampler = run(info)\n",
    "    nre.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8871c8-e5a1-490a-8e0c-5f63c488c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "if Run_NRE:\n",
    "    start_time = time()\n",
    "    updated_info_nre, sampler_nre = run(info_nre)\n",
    "    nre.time_this(start_time)\n",
    "else:\n",
    "    print('Chains (hopefully) exist!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee499df5-896d-458c-b680-459d3eb380cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Fig = True\n",
    "\n",
    "Show_MCMC = True\n",
    "Show_NRE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e4babe-7d7c-4ce6-96ba-ba330c2bbab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Burn_Frac = 0.3\n",
    "rng = np.random.RandomState(42)\n",
    "n_params = len(nre.prior_mean)\n",
    "dim = 1*n_params\n",
    "dof = ndata - n_paramsSetup\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "if Show_MCMC:\n",
    "    gd_sample = loadMCSamples(str(Path(info[\"output\"]).resolve()),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample.label = 'MCMC' \n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat = gd_sample.getCovMat().matrix[:dim, :dim]\n",
    "    sample = gd_sample.samples\n",
    "    sample = sample.T\n",
    "    ibest = sample[-2].argmin()\n",
    "    mcmc_best = sample[:dim,ibest]\n",
    "    mcmc_chi2 = sample[-2,ibest]\n",
    "    pval = sysp.gammainc(mcmc_chi2/2,dof/2)\n",
    "    mcmc_sig = np.sqrt(np.diag(mcmc_covmat))\n",
    "    print('MCMC...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_best])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2,dof,mcmc_chi2/dof,pval))\n",
    "\n",
    "if Show_NRE:\n",
    "    gd_sample_nre = loadMCSamples(str(Path(info_nre[\"output\"]).resolve()),settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample_nre.label = 'NRE ({0:s},{1:s},{2:s};{3:s})'.format(archs[NRE_Id]['N1'],archs[NRE_Id]['N2'],\n",
    "                                                                 archs[NRE_Id]['N3'],archs[NRE_Id]['Ns_str'])\n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat_nre = gd_sample_nre.getCovMat().matrix[:dim, :dim]\n",
    "    sample_nre = gd_sample_nre.samples\n",
    "    sample_nre = sample_nre.T\n",
    "    iNRE_Id = sample_nre[-2].argmin()\n",
    "    mcmc_NRE_Id = sample_nre[:dim,iNRE_Id]\n",
    "    mcmc_chi2_nre = sample_nre[-2,iNRE_Id]\n",
    "    pval_nre = sysp.gammainc(mcmc_chi2_nre/2,dof/2)\n",
    "    mcmc_sig_nre = np.sqrt(np.diag(mcmc_covmat_nre))\n",
    "    print('NN...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_NRE_Id])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_nre])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_nre,dof,mcmc_chi2_nre/dof,pval_nre))\n",
    "\n",
    "plot_param_list = Params_List\n",
    "Subplot_Size = 2.5\n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter(subplot_size=Subplot_Size)\n",
    "gdplot.settings.num_plot_contours = 3\n",
    "gdplot.settings.axes_fontsize = FS3\n",
    "gdplot.settings.axes_labelsize = FS2\n",
    "gdplot.settings.title_limit_fontsize = FS3\n",
    "\n",
    "show_list = []\n",
    "fill_list = []\n",
    "col_list = []\n",
    "if Show_MCMC:\n",
    "    show_list.append(gd_sample)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('indigo')\n",
    "if Show_NRE:\n",
    "    show_list.append(gd_sample_nre)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('crimson')\n",
    "gdplot.triangle_plot(show_list, plot_param_list,filled=fill_list,\n",
    "                     contour_colors=col_list,legend_loc='upper right',\n",
    "                     title_limit=0)\n",
    "for par_y in range(dim):\n",
    "    str_y = plot_param_list[par_y]\n",
    "    ax = gdplot.subplots[par_y,par_y]\n",
    "    if Show_MCMC:\n",
    "        ax.axvline(mcmc_best[par_y],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "    if Show_NRE:\n",
    "        ax.axvline(mcmc_NRE_Id[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "    for par_x in range(par_y):\n",
    "        str_x = plot_param_list[par_x]\n",
    "        ax = gdplot.subplots[par_y,par_x]\n",
    "        if Show_MCMC:\n",
    "            ax.scatter([mcmc_best[par_x]],[mcmc_best[par_y]],marker='*',s=50,c='aliceblue')\n",
    "            ax.axvline(mcmc_best[par_x],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_best[par_y],c='indigo',ls='--',lw=1.5,alpha=0.6)\n",
    "        if Show_NRE:\n",
    "            ax.scatter([mcmc_NRE_Id[par_x]],[mcmc_NRE_Id[par_y]],marker='*',s=50,c='peachpuff')\n",
    "            ax.axvline(mcmc_NRE_Id[par_x],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_NRE_Id[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "\n",
    "if Save_Fig:\n",
    "    filename = 'contours_'+File_Stem+'_nre{0:d}.png'.format(NRE_Id)\n",
    "    print('Writing to file: '+Plots_Dir+filename)\n",
    "    gdplot.export(fname=filename,adir=Plots_Dir)\n",
    "\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646fb857-2565-4bae-839d-e730cb4bd22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception('Needs work')\n",
    "\n",
    "# start_time = time()\n",
    "# # MCMC\n",
    "# if Show_MCMC:\n",
    "#     model.params = mnt.cv(mcmc_best[:dim])\n",
    "#     model_best = model.forward(mnt.X)[0]\n",
    "    \n",
    "#     N_Boot_Cobaya = np.min([1000,int(0.2*sample[0].size)])\n",
    "#     Ind = gd_sample.random_single_samples_indices(random_state=42,max_samples=N_Boot_Cobaya)\n",
    "#     N_Boot_Cobaya = Ind.size\n",
    "#     print('N_Boot_Cobaya: ',N_Boot_Cobaya)\n",
    "    \n",
    "#     model_boot = np.zeros((N_Boot_Cobaya,n_samp),dtype=float)\n",
    "    \n",
    "#     print('... extracting stats from subsample')\n",
    "#     for b in range(N_Boot_Cobaya):\n",
    "#         params_b = sample[:dim,Ind[b]] \n",
    "#         model.params = mnt.cv(params_b[:dim])\n",
    "#         model_boot[b] = model.forward(mnt.X)[0]\n",
    "#         mnt.status_bar(b,N_Boot_Cobaya)\n",
    "    \n",
    "#     model_16pc = np.percentile(model_boot,16,axis=0)\n",
    "#     model_84pc = np.percentile(model_boot,84,axis=0)\n",
    "\n",
    "#     del model_boot\n",
    "#     gc.collect()\n",
    "\n",
    "# # NN\n",
    "# if Show_NRE:\n",
    "#     model.params = mnt.cv(mcmc_NRE_Id[:dim])\n",
    "#     model_NRE_Id = model.forward(mnt.X)[0]\n",
    "    \n",
    "#     N_Boot_nre = np.min([1000,int(0.2*sample_nre[0].size)])\n",
    "#     Ind_nre = gd_sample_nre.random_single_samples_indices(random_state=42,max_samples=N_Boot_nre)\n",
    "#     N_Boot_nre = Ind_nre.size\n",
    "#     print('N_Boot_nre: ',N_Boot_nre)\n",
    "    \n",
    "#     model_boot_nre = np.zeros((N_Boot_nre,n_samp),dtype=float)\n",
    "    \n",
    "#     print('... extracting stats from subsample')\n",
    "#     for b in range(N_Boot_nre):\n",
    "#         params_b = sample_nre[:dim,Ind_nre[b]] \n",
    "#         model.params = mnt.cv(params_b[:dim])\n",
    "#         model_boot_nre[b] = model.forward(mnt.X)[0]\n",
    "#         mnt.status_bar(b,N_Boot_nre)\n",
    "    \n",
    "#     model_16pc_nre = np.percentile(model_boot_nre,16,axis=0)\n",
    "#     model_84pc_nre = np.percentile(model_boot_nre,84,axis=0)\n",
    "\n",
    "#     del model_boot_nre\n",
    "#     gc.collect()\n",
    "\n",
    "# cols = ['indigo','crimson','darkgreen']\n",
    "# plt.figure(figsize=(7,7))\n",
    "# plt.xlabel('x')\n",
    "# plt.ylabel('y')\n",
    "# if Model_Type == 'ps':\n",
    "#     plt.ylim(-1,6)\n",
    "# else:\n",
    "#     if n_comp == 1:\n",
    "#         plt.ylim(-1.5,1)\n",
    "#     else:\n",
    "#         plt.ylim(-1.5,3)\n",
    "# if Show_MCMC:\n",
    "#     plt.plot(mnt.X[0],model_best,'-',lw=1,c=cols[0],label='MCMC')\n",
    "#     plt.fill_between(mnt.X[0],model_84pc,model_16pc,color=cols[0],alpha=0.15)\n",
    "# if Show_NRE:\n",
    "#     plt.plot(mnt.X[0],model_NRE_Id,'-',lw=1,c=cols[1],label='NN')\n",
    "#     plt.fill_between(mnt.X[0],model_84pc_nre,model_16pc_nre,color=cols[1],alpha=0.15)\n",
    "\n",
    "# plt.errorbar(mnt.X[0],mnt.Y[0],yerr=sigma,c='k',ls='none',capsize=5,marker='o',markersize=4,label='data')\n",
    "\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.minorticks_on()\n",
    "# if Save_Fig:\n",
    "#     filename = Plots_Dir+'stats_'+File_Stem+'_nre{0:d}.png'.format(NRE_Id)\n",
    "#     print('Writing to file: '+filename)\n",
    "#     plt.savefig(filename,bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a863771-a131-478b-837a-e5d984c0c493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
