{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0aff408-aed4-41f1-aded-b79340f0ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys,shutil,os\n",
    "from scipy import linalg\n",
    "import scipy.special as sysp\n",
    "from scipy import stats \n",
    "\n",
    "sys.path.append('../code/')\n",
    "from sbi import NeuralRatioEstimator\n",
    "\n",
    "import copy,pickle\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import matplotlib as mpl\n",
    "import matplotlib.colors as pltcol\n",
    "import gc\n",
    "\n",
    "import psutil\n",
    "\n",
    "# cobaya imports\n",
    "from cobaya.run import run\n",
    "from cobaya.log import LoggedError\n",
    "from getdist.mcsamples import loadMCSamples\n",
    "import getdist.plots as gdplt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c6ee917-7dff-4549-b634-914c8ae8a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['xtick.top'] = True\n",
    "mpl.rcParams['ytick.right'] = True\n",
    "mpl.rcParams['xtick.labelsize'] = 14\n",
    "mpl.rcParams['ytick.labelsize'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 16\n",
    "mpl.rcParams['legend.fontsize'] = 12 # 14\n",
    "mpl.rcParams['legend.labelspacing'] = 0.3\n",
    "FS = 18\n",
    "FS2 = 15\n",
    "FS3 = 13\n",
    "FSL = 22\n",
    "\n",
    "mpl.rcParams['xtick.major.size'] = 6\n",
    "mpl.rcParams['xtick.minor.size'] = 3\n",
    "mpl.rcParams['ytick.major.size'] = 6\n",
    "mpl.rcParams['ytick.minor.size'] = 3\n",
    "\n",
    "#mpl.rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cba4f11-79a0-4174-b48d-644d2a4ff6e8",
   "metadata": {},
   "source": [
    "# Example usage of NeuralRatioEstimator\n",
    "### simple NRE using Sequential NN tested on (non-)linear Gaussian problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8130a605-fa19-4abf-aa29-be652a4ce4be",
   "metadata": {},
   "source": [
    "## Simulator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56875477-3b1c-4a65-b591-4b352edafe04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using file stem:poly_avg20\n",
      "Using plot dir :poly_avg20/plots/\n"
     ]
    }
   ],
   "source": [
    "nparam = 2\n",
    "ndata = 15\n",
    "\n",
    "NReal = 20\n",
    "\n",
    "File_Stem = 'poly' # 'poly','gaussmix'\n",
    "if (File_Stem == 'poly') & (nparam > 2):\n",
    "    File_Stem += '_deg{0:d}'.format(nparam-1)\n",
    "if NReal != 10:\n",
    "    File_Stem += '_avg{0:d}'.format(NReal)\n",
    "Plots_Dir = File_Stem + '/plots/'\n",
    "print('Using file stem:'+File_Stem)\n",
    "print('Using plot dir :'+Plots_Dir)\n",
    "\n",
    "class MyNRE(NeuralRatioEstimator):\n",
    "    def __init__(self,params={}):\n",
    "        NeuralRatioEstimator.__init__(self,params=params)\n",
    "\n",
    "        if self.file_stem[:8] == 'gaussmix':\n",
    "            if (self.nparam % 3) != 0:\n",
    "                raise ValueError(\"param_dim must be multiple of 3\")\n",
    "            self.ncomp = self.nparam // 3\n",
    "        \n",
    "        # data variables and noise\n",
    "        self.xvals = np.linspace(-1.5,3.5,self.ndata)\n",
    "        # self.sigma = 8*np.linspace(0.05,0.2,self.ndata)\n",
    "        self.sigma = np.linspace(0.1,0.5,ndata)\n",
    "        self.cov_mat = np.diagflat(self.sigma**2)\n",
    "\n",
    "        # prior mean,std\n",
    "        self.prior_mean = np.zeros(self.nparam)\n",
    "        self.prior_std = 6*np.ones(self.nparam)\n",
    "        self.prior_cov = np.diagflat(self.prior_std**2)\n",
    "\n",
    "        # # prior bounds\n",
    "        # self.theta_min = -10*np.ones(self.nparam)\n",
    "        # self.theta_max = 10*np.ones(self.nparam)\n",
    "        # self.dtheta = self.theta_max - self.theta_min        \n",
    "        \n",
    "        return\n",
    "    \n",
    "    def simulator(self,theta):\n",
    "        out = np.zeros((self.ndata,theta.shape[1]))\n",
    "        if self.file_stem[:4] == 'poly':\n",
    "            ####################\n",
    "            # polynomial\n",
    "            out += np.sum(np.array([np.outer(self.xvals**p,theta[p]) for p in range(self.nparam)]),axis=0)\n",
    "            # for x in range(self.xvals.size):\n",
    "            #     out[x] = np.sum([theta[p]*self.xvals[x]**p for p in range(self.nparam)])\n",
    "            ####################\n",
    "        else:\n",
    "            for c in range(self.ncomp):\n",
    "                amp = theta[c*3]\n",
    "                mu = theta[c*3+1]\n",
    "                mu = np.outer(np.ones(self.ndata),mu)\n",
    "                lnsig2 = theta[c*3+2]\n",
    "                # amp,mu,lnsig2 = theta[c*3:(c+1)*3,:]\n",
    "                out += amp*np.exp(-0.5*(self.xvals-mu.T).T**2/np.exp(lnsig2))\n",
    "\n",
    "        noise = self.rng.multivariate_normal(np.zeros(self.ndata),self.cov_mat,size=out.shape[1]) # shape (out.shape[1],out.shape[0])\n",
    "        out += noise.T\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def prior(self,nsamp):\n",
    "        theta = np.zeros((self.nparam,nsamp))\n",
    "        \n",
    "        for p in range(self.nparam):\n",
    "            theta[p] = self.prior_mean[p] + self.rng.randn(nsamp)*self.prior_std[p]\n",
    "            \n",
    "        # for p in range(self.nparam):\n",
    "        #     theta[p] = self.theta_min[p] + self.rng.rand(nsamp)*self.dtheta[p]\n",
    "        \n",
    "        return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138d5dbf-8110-4469-a0f0-432f3871f20a",
   "metadata": {},
   "source": [
    "## Analytical ratio for linear Gaussian problem\n",
    "#### with design matrix $\\mathcal{M}$, data $y$, data covariance $C$, prior inverse covariance $F_{\\rm (p)}$, prior mean $\\theta_{\\rm (p)}$, we have\n",
    "#### $F = \\mathcal{M}^{\\rm T}C^{-1}\\mathcal{M} + F_{\\rm (p)}$\n",
    "#### $\\hat\\theta = F^{-1}\\left(\\mathcal{M}^{\\rm T}C^{-1}y + F_{\\rm (p)}\\theta_{\\rm (p)}\\right)$\n",
    "#### $-2\\ln p(\\theta|x) = (\\theta-\\hat\\theta)^{\\rm T}\\,F\\,(\\theta-\\hat\\theta) - \\ln{\\rm det}F + M\\ln(2\\pi)$\n",
    "#### $-2\\ln p(\\theta) = (\\theta-\\theta_{\\rm (p)})^{\\rm T}\\,F_{\\rm (p)}\\,(\\theta-\\theta_{\\rm (p)}) - \\ln{\\rm det}F_{\\rm (p)} + M\\ln(2\\pi)$\n",
    "#### $2\\ln r(y,\\theta) = 2\\ln\\left[p(\\theta|y)/p(\\theta)\\right] = (\\mathcal{M}\\theta)^{\\rm T}C^{-1}(y-\\mathcal{M}\\theta) + \\left(\\mathcal{M}(\\theta-\\hat\\theta)\\right)^{\\rm T}C^{-1}y - (\\hat\\theta-\\theta_{\\rm (p)})^{\\rm T}F_{\\rm (p)}\\theta_{\\rm (p)} + \\ln\\,{\\rm det}(FF_{\\rm (p)}^{-1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4326d80c-a5b2-43f1-bd99-c0b2d9d112a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytical_nre(nre,X,theta):\n",
    "    designM = np.ones((nre.ndata,nre.nparam))\n",
    "    for p in range(nre.nparam):\n",
    "        designM[:,p] = nre.xvals**p # monomial basis\n",
    "    F_p = np.diagflat(1/nre.prior_std**2) # prior inv Cov\n",
    "    theta_p = nre.cv(nre.prior_mean) # prior mean\n",
    "    Cinv,detC = nre.svd_inv(nre.cov_mat) #np.diagflat(1/nre.sigma**2) # data inv Cov\n",
    "    F = F_p + np.dot(designM.T,np.dot(Cinv,designM)) # posterior inv Cov\n",
    "    theta_hat = np.dot(F_p,theta_p) # posterior mean\n",
    "    theta_hat += np.dot(designM.T,np.dot(Cinv,X))\n",
    "    theta_hat = np.dot(linalg.inv(F),theta_hat)\n",
    "\n",
    "    Mtheta = np.dot(designM,theta)\n",
    "    Mtheta_hat = np.dot(designM,theta_hat)\n",
    "\n",
    "    lnr = np.dot(Mtheta.T,np.dot(Cinv,X-Mtheta))\n",
    "    lnr += np.dot((Mtheta-Mtheta_hat).T,np.dot(Cinv,X))\n",
    "    lnr -= np.dot((theta_hat-theta_p).T,np.dot(F_p,theta_p))\n",
    "    lnr += np.log(linalg.det(F)) - np.log(linalg.det(F_p))\n",
    "    lnr *= 0.5\n",
    "    ratio = np.exp(lnr)    \n",
    "    return ratio,F,theta_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b76ac1-4cf8-4683-a4e4-902734a1ae95",
   "metadata": {},
   "source": [
    "## NRE setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ea77ddc-634a-43bf-a4b7-5d6ded8c0e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup...\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "\n",
      "NFree = 184701; NSamp = 184701\n",
      "\n",
      "... setup complete with file stem: poly_avg20/C34114459401\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "Sample setup...\n",
      "Sharing data between 20 realisations...\n",
      "Training 20 realisations with 20 processors...\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "... training\n",
      "[.....               ] 26% done.                   ] 5% done[.                   ] 5% done\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "[.....               ] 27% done\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "[.....               ] 27% done\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "[.....               ] 27% done\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "[.....               ] 28% done\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "[.....               ] 28% done\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "\n",
      "... saving training/validation loss history\n",
      "... loading best network\n",
      "... ... done\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "... setting up 3 layer feed-forward neural network\n",
      "... ... expecting data dim = 17, target dim = 1\n",
      "... ... using hidden layers of sizes [500,350]\n",
      "... ... ... and activations [tanh,tanh]\n",
      "... ... using last activation layer 'sigm'\n",
      "... ... ... with threshold (None means default): None\n",
      "... ... using loss function 'nll'\n",
      "... ... not using any regularization\n",
      "... ... not using any weight decay\n",
      "params_train: {'max_epoch': 20000, 'lrate': 3e-05, 'check_after': 5000, 'mb_count': 384, 'val_frac': 0.2}\n",
      "5990 min 51.28 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Train = True\n",
    "\n",
    "ValFrac = 0.2\n",
    "\n",
    "start_time = time()\n",
    "if Train:\n",
    "    Parallel = True\n",
    "    \n",
    "    L1 = 1 # 1 # number of layers with first activation\n",
    "    AType1 = 'tanh' # 'tanh'\n",
    "    NNodes1 = 500 # 10,30,50,100,150,300,500\n",
    "    L2 = 1 # 1 # number of layers with second activation\n",
    "    AType2 = 'tanh' # 'tanh'\n",
    "    NNodes2 = 350 # 7,20,35,70,100,200,350\n",
    "    L3 = 0 # 1 # number of layers with third activation\n",
    "    AType3 = 'lrelu' # 'tanh'\n",
    "    NNodes3 = 0 # 20\n",
    "        \n",
    "    Share_Train_Data = True # True is more efficient (as expected) as well as higher quality (for some reason)\n",
    "    \n",
    "    Standardize = True\n",
    "    Weight_Decay = 0.0 # 0.0\n",
    "    LReLU_Slope = 1.5e-2 # 1e-2\n",
    "    \n",
    "    params = {'param_dim':nparam,'data_dim':ndata,'standardize':Standardize,'lrelu_slope':LReLU_Slope,\n",
    "              'Lh':L1+L2+L3,'n_hidden_layer':[NNodes1]*L1+[NNodes2]*L2+[NNodes3]*L3,'hidden_atypes':[AType1]*L1+[AType2]*L2+[AType3]*L3,\n",
    "              'wt_decay':Weight_Decay,'file_stem':File_Stem,'nreal':NReal,'parallel':Parallel,'share_train_data':Share_Train_Data}\n",
    "    \n",
    "    print('Setup...')\n",
    "    nre_setup = MyNRE(params=params)\n",
    "    NFree = nre_setup.net[1].calc_N_freeparams()\n",
    "\n",
    "    Fac = 0.8 # 0.8,1,2,4\n",
    "    NSamp = int(Fac*NFree/(1-ValFrac)) # 1*NFree \n",
    "    # NSamp = 50000 # 100k,50k    \n",
    "    Complexity = NFree*NSamp\n",
    "    # NSamp = 50000 # 640000 # ensure multiple of 100\n",
    "    # Complexity = NFree*NSamp//100\n",
    "    del nre_setup\n",
    "    print('\\nNFree = {0:d}; NSamp = {1:d}\\n'.format(NFree,NSamp))\n",
    "    \n",
    "    if NReal > 1:\n",
    "        for r in range(1,NReal+1):\n",
    "            Path(File_Stem+'/r{0:d}'.format(r)).rmdir()\n",
    "\n",
    "    File_Stem_This = File_Stem + '/C{0:d}'.format(Complexity)\n",
    "    params['file_stem'] = File_Stem_This\n",
    "    print('... setup complete with file stem:',params['file_stem'])\n",
    "        \n",
    "    if Train:\n",
    "        nre = MyNRE(params=params)\n",
    "        params_train = {'max_epoch':20000, # 16000\n",
    "                        'lrate':3e-5, # 3e-5\n",
    "                        'check_after':5000, # 1000\n",
    "                        'mb_count':int(np.sqrt((1-ValFrac)*NSamp)),'val_frac':ValFrac}\n",
    "        nre.train(NSamp,params=params_train)\n",
    "        nre.save()\n",
    "        nre.save_train(params_train)\n",
    "else:\n",
    "    #######################\n",
    "    # NReal = 20 (multi KL)\n",
    "    # progressive arch, proportional train size (train=0.8*free): 320445801,4329771601,34114459401\n",
    "    #######################\n",
    "    # NReal = 10 (multi KL)\n",
    "    # progressive arch, proportional train size (train=4*free): 351125,6973805,37019205,399707405,1602229005,21648858005\n",
    "    # progressive arch, proportional train size (train=2*free): 175430,3486312,18508242,199849232,801105552,10824396102\n",
    "    # progressive arch, proportional train size (train=free): 87715,1743156,9254121,99924616,400552776,5412198051\n",
    "    # progressive arch, proportional train size (train=0.8*free): 70225,194481,1394761,7403841,27050401,79941481,320445801,\n",
    "    #                                                             4329771601,34114459401\n",
    "    # fixed arch (50,35), progressive train size: 5442000,9251400,13605000,27210000\n",
    "    # fixed arch (100,70), progressive train size: 17882000,44705000,100139200,178820000\n",
    "    # fixed arch (500,350), progressive train size: 9235050000,18470100000\n",
    "    #######################\n",
    "    # NReal = 5\n",
    "    # 483,723,2410,4410,27210,52010,81630,89410,156030,268230,272100,\n",
    "    # 846100,894100,1200100,1790100,2682300,8941000\n",
    "    #######################\n",
    "    Complexity = 34114459401\n",
    "    File_Stem_This = File_Stem + '/C{0:d}'.format(Complexity)\n",
    "\n",
    "# done like this to properly update saved loss histories in parallel calculation\n",
    "with open(File_Stem_This + '/params.pkl', 'rb') as f:\n",
    "    params = pickle.load(f)  \n",
    "nre = MyNRE(params=params)\n",
    "nre.load()\n",
    "params_train = nre.load_train()\n",
    "    \n",
    "print('params_train:',params_train)\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13d249e2-e8b2-48df-8830-6de30acbe434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min val loss...\n",
      "... r1 = 1.310e-03\n",
      "... r2 = 1.125e-03\n",
      "... r3 = 1.462e-03\n",
      "... r4 = 1.312e-03\n",
      "... r5 = 2.061e-03\n",
      "... r6 = 1.311e-03\n",
      "... r7 = 1.857e-03\n",
      "... r8 = 1.313e-03\n",
      "... r9 = 1.668e-03\n",
      "... r10 = 1.243e-03\n",
      "... r11 = 1.519e-03\n",
      "... r12 = 1.877e-03\n",
      "... r13 = 1.497e-03\n",
      "... r14 = 1.941e-03\n",
      "... r15 = 1.166e-03\n",
      "... r16 = 1.934e-03\n",
      "... r17 = 1.152e-03\n",
      "... r18 = 7.820e-04\n",
      "... r19 = 2.216e-03\n",
      "... r20 = 1.369e-03\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('min val loss...')\n",
    "plt.yscale('log')\n",
    "for r in range(1,NReal+1):\n",
    "    min_val_loss = nre.net[r].val_loss[nre.net[r].val_loss > 0.0].min()\n",
    "    print('... r{0:d} = {1:.3e}'.format(r,min_val_loss))\n",
    "    plt.plot(nre.net[r].epochs,nre.net[r].training_loss,'k-',lw=0.5)\n",
    "    plt.plot(nre.net[r].epochs,nre.net[r].val_loss,'r-',lw=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440ba180-b702-4343-a11b-cca0a011872c",
   "metadata": {},
   "source": [
    "## MCMC-based comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ae61e55-7a1f-437a-be4a-bc409a7b5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:poly_avg20/C34114459401 ...\n",
      "... setting up tasks\n",
      "[....................] 100% done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[vivaldi-primo:851090] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:851092] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:851087] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:851095] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:851244] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:0.6931215, a1:-7.997969\n",
      "Current result: LogPosterior(logpost=5.122072371516099, logpriors=[-6.316506070996077], loglikes=array([11.43857844]), derived=[], finite=False)\n",
      "Last proposal: [20.03374182 -9.30300438]\n",
      "With rejected result: LogPosterior(logpost=-50.17788486071569, logpriors=[-12.19773908649477], loglikes=array([-37.98014577]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:0.6931215, a1:-7.997969\n",
      "Current result: LogPosterior(logpost=5.122072371516099, logpriors=[-6.316506070996077], loglikes=array([11.43857844]), derived=[], finite=False)\n",
      "Last proposal: [20.03374182 -9.30300438]\n",
      "With rejected result: LogPosterior(logpost=-50.17788486071569, logpriors=[-12.19773908649477], loglikes=array([-37.98014577]), derived=[], finite=False)\n",
      "[vivaldi-primo:851310] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:6.908194, a1:-9.278113\n",
      "Current result: LogPosterior(logpost=14.200729521421913, logpriors=[-7.279819853804362], loglikes=array([21.48054938]), derived=[], finite=False)\n",
      "Last proposal: [11.96372719 -7.31660374]\n",
      "With rejected result: LogPosterior(logpost=-43.017117859234745, logpriors=[-8.152832931513302], loglikes=array([-34.86428493]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:6.908194, a1:-9.278113\n",
      "Current result: LogPosterior(logpost=14.200729521421913, logpriors=[-7.279819853804362], loglikes=array([21.48054938]), derived=[], finite=False)\n",
      "Last proposal: [11.96372719 -7.31660374]\n",
      "With rejected result: LogPosterior(logpost=-43.017117859234745, logpriors=[-8.152832931513302], loglikes=array([-34.86428493]), derived=[], finite=False)\n",
      "[vivaldi-primo:851533] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:851640] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.460434, a1:-2.909892\n",
      "Current result: LogPosterior(logpost=3.1059647524915643, logpriors=[-5.815325759827925], loglikes=array([8.92129051]), derived=[], finite=False)\n",
      "Last proposal: [ -3.37583012 -11.87358727]\n",
      "With rejected result: LogPosterior(logpost=-33.293013028292954, logpriors=[-7.537761332990666], loglikes=array([-25.7552517]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.460434, a1:-2.909892\n",
      "Current result: LogPosterior(logpost=3.1059647524915643, logpriors=[-5.815325759827925], loglikes=array([8.92129051]), derived=[], finite=False)\n",
      "Last proposal: [ -3.37583012 -11.87358727]\n",
      "With rejected result: LogPosterior(logpost=-33.293013028292954, logpriors=[-7.537761332990666], loglikes=array([-25.7552517]), derived=[], finite=False)\n",
      "[vivaldi-primo:851704] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:851789] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.47753, a1:3.584037\n",
      "Current result: LogPosterior(logpost=4.931799949922389, logpriors=[-5.878251430725162], loglikes=array([10.81005138]), derived=[], finite=False)\n",
      "Last proposal: [ 1.77678903 11.74949464]\n",
      "With rejected result: LogPosterior(logpost=-47.20384415465056, logpriors=[-7.382612720387514], loglikes=array([-39.82123143]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.47753, a1:3.584037\n",
      "Current result: LogPosterior(logpost=4.931799949922389, logpriors=[-5.878251430725162], loglikes=array([10.81005138]), derived=[], finite=False)\n",
      "Last proposal: [ 1.77678903 11.74949464]\n",
      "With rejected result: LogPosterior(logpost=-47.20384415465056, logpriors=[-7.382612720387514], loglikes=array([-39.82123143]), derived=[], finite=False)\n",
      "[vivaldi-primo:851872] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852127] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852212] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852315] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:13.62263, a1:8.156667\n",
      "Current result: LogPosterior(logpost=15.169643858637649, logpriors=[-8.922887570078704], loglikes=array([24.09253143]), derived=[], finite=False)\n",
      "Last proposal: [12.00955899 13.02363318]\n",
      "With rejected result: LogPosterior(logpost=-32.09582791052163, logpriors=[-9.780347786597748], loglikes=array([-22.31548012]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:13.62263, a1:8.156667\n",
      "Current result: LogPosterior(logpost=15.169643858637649, logpriors=[-8.922887570078704], loglikes=array([24.09253143]), derived=[], finite=False)\n",
      "Last proposal: [12.00955899 13.02363318]\n",
      "With rejected result: LogPosterior(logpost=-32.09582791052163, logpriors=[-9.780347786597748], loglikes=array([-22.31548012]), derived=[], finite=False)\n",
      "[vivaldi-primo:852445] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852643] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852689] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:3.722478, a1:5.174082\n",
      "Current result: LogPosterior(logpost=4.211323909687688, logpriors=[-5.985673383483843], loglikes=array([10.19699729]), derived=[], finite=False)\n",
      "Last proposal: [-12.88521278   1.8286489 ]\n",
      "With rejected result: LogPosterior(logpost=-35.20630601899705, logpriors=[-7.773794133281997], loglikes=array([-27.43251189]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:3.722478, a1:5.174082\n",
      "Current result: LogPosterior(logpost=4.211323909687688, logpriors=[-5.985673383483843], loglikes=array([10.19699729]), derived=[], finite=False)\n",
      "Last proposal: [-12.88521278   1.8286489 ]\n",
      "With rejected result: LogPosterior(logpost=-35.20630601899705, logpriors=[-7.773794133281997], loglikes=array([-27.43251189]), derived=[], finite=False)\n",
      "[vivaldi-primo:852775] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852838] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-3.898422, a1:7.506561\n",
      "Current result: LogPosterior(logpost=3.678363283752594, logpriors=[-6.415092571631952], loglikes=array([10.09345586]), derived=[], finite=False)\n",
      "Last proposal: [-23.57270649  43.96284685]\n",
      "With rejected result: LogPosterior(logpost=-63.77781337972275, logpriors=[-39.982568151488195], loglikes=array([-23.79524523]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-3.898422, a1:7.506561\n",
      "Current result: LogPosterior(logpost=3.678363283752594, logpriors=[-6.415092571631952], loglikes=array([10.09345586]), derived=[], finite=False)\n",
      "Last proposal: [-23.57270649  43.96284685]\n",
      "With rejected result: LogPosterior(logpost=-63.77781337972275, logpriors=[-39.982568151488195], loglikes=array([-23.79524523]), derived=[], finite=False)\n",
      "[vivaldi-primo:852896] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:852951] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:0.7041983, a1:-3.010901\n",
      "Current result: LogPosterior(logpost=3.3249737085761852, logpriors=[-5.554193530971731], loglikes=array([8.87916724]), derived=[], finite=False)\n",
      "Last proposal: [22.50201368  8.83231962]\n",
      "With rejected result: LogPosterior(logpost=-47.02626991842389, logpriors=[-13.537375029228519], loglikes=array([-33.48889489]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-42:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:0.7041983, a1:-3.010901\n",
      "Current result: LogPosterior(logpost=3.3249737085761852, logpriors=[-5.554193530971731], loglikes=array([8.87916724]), derived=[], finite=False)\n",
      "Last proposal: [22.50201368  8.83231962]\n",
      "With rejected result: LogPosterior(logpost=-47.02626991842389, logpriors=[-13.537375029228519], loglikes=array([-33.48889489]), derived=[], finite=False)\n",
      "[vivaldi-primo:853024] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-1.292609, a1:4.849274\n",
      "Current result: LogPosterior(logpost=2.4616917502546665, logpriors=[-5.771205661146568], loglikes=array([8.23289741]), derived=[], finite=False)\n",
      "Last proposal: [ 30.26124946 -19.26261757]\n",
      "With rejected result: LogPosterior(logpost=-54.42828086220072, logpriors=[-23.293502317919593], loglikes=array([-31.13477854]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-41:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-1.292609, a1:4.849274\n",
      "Current result: LogPosterior(logpost=2.4616917502546665, logpriors=[-5.771205661146568], loglikes=array([8.23289741]), derived=[], finite=False)\n",
      "Last proposal: [ 30.26124946 -19.26261757]\n",
      "With rejected result: LogPosterior(logpost=-54.42828086220072, logpriors=[-23.293502317919593], loglikes=array([-31.13477854]), derived=[], finite=False)\n",
      "[vivaldi-primo:853089] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-0.1959334, a1:7.910142\n",
      "Current result: LogPosterior(logpost=2.844484307696594, logpriors=[-6.290961831229997], loglikes=array([9.13544614]), derived=[], finite=False)\n",
      "Last proposal: [ 2.73940367 -1.11078923]\n",
      "With rejected result: LogPosterior(logpost=-36.55851306867938, logpriors=[-5.542759688032151], loglikes=array([-31.01575338]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-45:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-0.1959334, a1:7.910142\n",
      "Current result: LogPosterior(logpost=2.844484307696594, logpriors=[-6.290961831229997], loglikes=array([9.13544614]), derived=[], finite=False)\n",
      "Last proposal: [ 2.73940367 -1.11078923]\n",
      "With rejected result: LogPosterior(logpost=-36.55851306867938, logpriors=[-5.542759688032151], loglikes=array([-31.01575338]), derived=[], finite=False)\n",
      "[vivaldi-primo:853246] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:853356] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:853417] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-6.98435, a1:-4.391397\n",
      "Current result: LogPosterior(logpost=3.930451045962963, logpriors=[-6.366750289287788], loglikes=array([10.29720134]), derived=[], finite=False)\n",
      "Last proposal: [6.02696692 3.0533475 ]\n",
      "With rejected result: LogPosterior(logpost=-45.39785415723761, logpriors=[-6.0553857442589205], loglikes=array([-39.34246841]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-47:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-6.98435, a1:-4.391397\n",
      "Current result: LogPosterior(logpost=3.930451045962963, logpriors=[-6.366750289287788], loglikes=array([10.29720134]), derived=[], finite=False)\n",
      "Last proposal: [6.02696692 3.0533475 ]\n",
      "With rejected result: LogPosterior(logpost=-45.39785415723761, logpriors=[-6.0553857442589205], loglikes=array([-39.34246841]), derived=[], finite=False)\n",
      "[vivaldi-primo:853487] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:7.592056, a1:8.258869\n",
      "Current result: LogPosterior(logpost=10.119169859988281, logpriors=[-7.169288230907503], loglikes=array([17.28845809]), derived=[], finite=False)\n",
      "Last proposal: [13.81828581 22.76085635]\n",
      "With rejected result: LogPosterior(logpost=-44.260128944338916, logpriors=[-15.268640514236099], loglikes=array([-28.99148843]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-48:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:7.592056, a1:8.258869\n",
      "Current result: LogPosterior(logpost=10.119169859988281, logpriors=[-7.169288230907503], loglikes=array([17.28845809]), derived=[], finite=False)\n",
      "Last proposal: [13.81828581 22.76085635]\n",
      "With rejected result: LogPosterior(logpost=-44.260128944338916, logpriors=[-15.268640514236099], loglikes=array([-28.99148843]), derived=[], finite=False)\n",
      "[vivaldi-primo:853574] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:853866] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-10.27359, a1:1.970736\n",
      "Current result: LogPosterior(logpost=7.794293666385216, logpriors=[-6.941262387285161], loglikes=array([14.73555605]), derived=[], finite=False)\n",
      "Last proposal: [-15.59156041 -44.00130241]\n",
      "With rejected result: LogPosterior(logpost=-47.81868427633815, logpriors=[-35.688220587576666], loglikes=array([-12.13046369]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-51:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-10.27359, a1:1.970736\n",
      "Current result: LogPosterior(logpost=7.794293666385216, logpriors=[-6.941262387285161], loglikes=array([14.73555605]), derived=[], finite=False)\n",
      "Last proposal: [-15.59156041 -44.00130241]\n",
      "With rejected result: LogPosterior(logpost=-47.81868427633815, logpriors=[-35.688220587576666], loglikes=array([-12.13046369]), derived=[], finite=False)\n",
      "[vivaldi-primo:853966] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:854023] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:854110] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:5.367977, a1:3.387553\n",
      "Current result: LogPosterior(logpost=1.2147105303366468, logpriors=[-5.980988922666296], loglikes=array([7.19569945]), derived=[], finite=False)\n",
      "Last proposal: [ 6.3746216  12.24459223]\n",
      "With rejected result: LogPosterior(logpost=-45.28935721018331, logpriors=[-8.068143775288014], loglikes=array([-37.22121343]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-54:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:5.367977, a1:3.387553\n",
      "Current result: LogPosterior(logpost=1.2147105303366468, logpriors=[-5.980988922666296], loglikes=array([7.19569945]), derived=[], finite=False)\n",
      "Last proposal: [ 6.3746216  12.24459223]\n",
      "With rejected result: LogPosterior(logpost=-45.28935721018331, logpriors=[-8.068143775288014], loglikes=array([-37.22121343]), derived=[], finite=False)\n",
      "[vivaldi-primo:854212] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:854399] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:854515] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.174317, a1:8.859286\n",
      "Current result: LogPosterior(logpost=7.510375789546201, logpriors=[-6.7535052902311214], loglikes=array([14.26388108]), derived=[], finite=False)\n",
      "Last proposal: [ 8.77264405 13.7977985 ]\n",
      "With rejected result: LogPosterior(logpost=-35.22344476995116, logpriors=[-9.134431102378713], loglikes=array([-26.08901367]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-57:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.174317, a1:8.859286\n",
      "Current result: LogPosterior(logpost=7.510375789546201, logpriors=[-6.7535052902311214], loglikes=array([14.26388108]), derived=[], finite=False)\n",
      "Last proposal: [ 8.77264405 13.7977985 ]\n",
      "With rejected result: LogPosterior(logpost=-35.22344476995116, logpriors=[-9.134431102378713], loglikes=array([-26.08901367]), derived=[], finite=False)\n",
      "[vivaldi-primo:854595] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-4.832, a1:1.591728\n",
      "Current result: LogPosterior(logpost=3.905521569169797, logpriors=[-5.78086575305779], loglikes=array([9.68638732]), derived=[], finite=False)\n",
      "Last proposal: [-1.65170933  2.61443426]\n",
      "With rejected result: LogPosterior(logpost=-47.60150914141364, logpriors=[-5.554221146425576], loglikes=array([-42.04728799]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-58:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-4.832, a1:1.591728\n",
      "Current result: LogPosterior(logpost=3.905521569169797, logpriors=[-5.78086575305779], loglikes=array([9.68638732]), derived=[], finite=False)\n",
      "Last proposal: [-1.65170933  2.61443426]\n",
      "With rejected result: LogPosterior(logpost=-47.60150914141364, logpriors=[-5.554221146425576], loglikes=array([-42.04728799]), derived=[], finite=False)\n",
      "[vivaldi-primo:854674] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:854826] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:854886] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-5.794874, a1:-6.286841\n",
      "Current result: LogPosterior(logpost=5.563224280836594, logpriors=[-6.43674234566823], loglikes=array([11.99996663]), derived=[], finite=False)\n",
      "Last proposal: [3.55365403 4.8214354 ]\n",
      "With rejected result: LogPosterior(logpost=-45.79789978715118, logpriors=[-5.919655674856808], loglikes=array([-39.87824411]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-61:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-5.794874, a1:-6.286841\n",
      "Current result: LogPosterior(logpost=5.563224280836594, logpriors=[-6.43674234566823], loglikes=array([11.99996663]), derived=[], finite=False)\n",
      "Last proposal: [3.55365403 4.8214354 ]\n",
      "With rejected result: LogPosterior(logpost=-45.79789978715118, logpriors=[-5.919655674856808], loglikes=array([-39.87824411]), derived=[], finite=False)\n",
      "[vivaldi-primo:854982] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:5.455626, a1:5.90811\n",
      "Current result: LogPosterior(logpost=2.8248362898860027, logpriors=[-6.319585133618528], loglikes=array([9.14442142]), derived=[], finite=False)\n",
      "Last proposal: [-13.93365694  -0.81888816]\n",
      "With rejected result: LogPosterior(logpost=-30.47550225501051, logpriors=[-8.127192857997407], loglikes=array([-22.3483094]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-62:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:5.455626, a1:5.90811\n",
      "Current result: LogPosterior(logpost=2.8248362898860027, logpriors=[-6.319585133618528], loglikes=array([9.14442142]), derived=[], finite=False)\n",
      "Last proposal: [-13.93365694  -0.81888816]\n",
      "With rejected result: LogPosterior(logpost=-30.47550225501051, logpriors=[-8.127192857997407], loglikes=array([-22.3483094]), derived=[], finite=False)\n",
      "[vivaldi-primo:855089] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:7.150892, a1:-9.518582\n",
      "Current result: LogPosterior(logpost=11.789859175176776, logpriors=[-7.389988650972509], loglikes=array([19.17984783]), derived=[], finite=False)\n",
      "Last proposal: [ 7.35992591 -8.53492277]\n",
      "With rejected result: LogPosterior(logpost=-28.37803564621012, logpriors=[-7.185471227397414], loglikes=array([-21.19256442]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-59:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:7.150892, a1:-9.518582\n",
      "Current result: LogPosterior(logpost=11.789859175176776, logpriors=[-7.389988650972509], loglikes=array([19.17984783]), derived=[], finite=False)\n",
      "Last proposal: [ 7.35992591 -8.53492277]\n",
      "With rejected result: LogPosterior(logpost=-28.37803564621012, logpriors=[-7.185471227397414], loglikes=array([-21.19256442]), derived=[], finite=False)\n",
      "[vivaldi-primo:855152] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.223829, a1:-5.895141\n",
      "Current result: LogPosterior(logpost=4.289487989348961, logpriors=[-6.1518602681401955], loglikes=array([10.44134826]), derived=[], finite=False)\n",
      "Last proposal: [ -8.88534829 -10.047726  ]\n",
      "With rejected result: LogPosterior(logpost=-32.93471701913018, logpriors=[-7.920093393421459], loglikes=array([-25.01462363]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-64:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:4.223829, a1:-5.895141\n",
      "Current result: LogPosterior(logpost=4.289487989348961, logpriors=[-6.1518602681401955], loglikes=array([10.44134826]), derived=[], finite=False)\n",
      "Last proposal: [ -8.88534829 -10.047726  ]\n",
      "With rejected result: LogPosterior(logpost=-32.93471701913018, logpriors=[-7.920093393421459], loglikes=array([-25.01462363]), derived=[], finite=False)\n",
      "[vivaldi-primo:855250] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:3.209589, a1:10.97499\n",
      "Current result: LogPosterior(logpost=12.800633023946169, logpriors=[-7.237393260919759], loglikes=array([20.03802628]), derived=[], finite=False)\n",
      "Last proposal: [7.79872469 9.72710795]\n",
      "With rejected result: LogPosterior(logpost=-38.94037243666005, logpriors=[-7.580239558059635], loglikes=array([-31.36013288]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-65:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:3.209589, a1:10.97499\n",
      "Current result: LogPosterior(logpost=12.800633023946169, logpriors=[-7.237393260919759], loglikes=array([20.03802628]), derived=[], finite=False)\n",
      "Last proposal: [7.79872469 9.72710795]\n",
      "With rejected result: LogPosterior(logpost=-38.94037243666005, logpriors=[-7.580239558059635], loglikes=array([-31.36013288]), derived=[], finite=False)\n",
      "[vivaldi-primo:855344] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:855379] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:855418] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:0.518001, a1:6.69519\n",
      "Current result: LogPosterior(logpost=4.7500785036717605, logpriors=[-6.047700123971106], loglikes=array([10.79777863]), derived=[], finite=False)\n",
      "Last proposal: [-18.83863769  32.99836062]\n",
      "With rejected result: LogPosterior(logpost=-49.068541650909744, logpriors=[-25.473980361774203], loglikes=array([-23.59456129]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-66:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:0.518001, a1:6.69519\n",
      "Current result: LogPosterior(logpost=4.7500785036717605, logpriors=[-6.047700123971106], loglikes=array([10.79777863]), derived=[], finite=False)\n",
      "Last proposal: [-18.83863769  32.99836062]\n",
      "With rejected result: LogPosterior(logpost=-49.068541650909744, logpriors=[-25.473980361774203], loglikes=array([-23.59456129]), derived=[], finite=False)\n",
      "[vivaldi-primo:855542] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:855618] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:10.74057, a1:1.494341\n",
      "Current result: LogPosterior(logpost=7.244872111178295, logpriors=[-7.0546301777422284], loglikes=array([14.29950229]), derived=[], finite=False)\n",
      "Last proposal: [ 13.64571377 -10.57520616]\n",
      "With rejected result: LogPosterior(logpost=-27.592170647069256, logpriors=[-9.56084724897445], loglikes=array([-18.0313234]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-70:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:10.74057, a1:1.494341\n",
      "Current result: LogPosterior(logpost=7.244872111178295, logpriors=[-7.0546301777422284], loglikes=array([14.29950229]), derived=[], finite=False)\n",
      "Last proposal: [ 13.64571377 -10.57520616]\n",
      "With rejected result: LogPosterior(logpost=-27.592170647069256, logpriors=[-9.56084724897445], loglikes=array([-18.0313234]), derived=[], finite=False)\n",
      "[vivaldi-primo:855707] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n",
      "[vivaldi-primo:855744] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-8.245288, a1:9.376988\n",
      "Current result: LogPosterior(logpost=9.149825276910777, logpriors=[-7.586849941726706], loglikes=array([16.73667522]), derived=[], finite=False)\n",
      "Last proposal: [-7.49039221 18.17723429]\n",
      "With rejected result: LogPosterior(logpost=-37.86646229429519, logpriors=[-10.789699089812885], loglikes=array([-27.0767632]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-69:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-8.245288, a1:9.376988\n",
      "Current result: LogPosterior(logpost=9.149825276910777, logpriors=[-7.586849941726706], loglikes=array([16.73667522]), derived=[], finite=False)\n",
      "Last proposal: [-7.49039221 18.17723429]\n",
      "With rejected result: LogPosterior(logpost=-37.86646229429519, logpriors=[-10.789699089812885], loglikes=array([-27.0767632]), derived=[], finite=False)\n",
      "[vivaldi-primo:855858] mca_base_component_repository_open: unable to open mca_btl_openib: librdmacm.so.1: cannot open shared object file: No such file or directory (ignored)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:2.776707, a1:-6.047186\n",
      "Current result: LogPosterior(logpost=3.684332957253604, logpriors=[-6.03637596299761], loglikes=array([9.72070892]), derived=[], finite=False)\n",
      "Last proposal: [3.90005907 5.94843161]\n",
      "With rejected result: LogPosterior(logpost=-47.53461246582499, logpriors=[-6.124094607743111], loglikes=array([-41.41051786]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-71:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:2.776707, a1:-6.047186\n",
      "Current result: LogPosterior(logpost=3.684332957253604, logpriors=[-6.03637596299761], loglikes=array([9.72070892]), derived=[], finite=False)\n",
      "Last proposal: [3.90005907 5.94843161]\n",
      "With rejected result: LogPosterior(logpost=-47.53461246582499, logpriors=[-6.124094607743111], loglikes=array([-41.41051786]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:11.1332, a1:-1.211297\n",
      "Current result: LogPosterior(logpost=4.320494454796981, logpriors=[-7.163277093525101], loglikes=array([11.48377155]), derived=[], finite=False)\n",
      "Last proposal: [-1.46534041  4.38626909]\n",
      "With rejected result: LogPosterior(logpost=-36.954552255918486, logpriors=[-5.718431825416216], loglikes=array([-31.23612043]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-73:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:11.1332, a1:-1.211297\n",
      "Current result: LogPosterior(logpost=4.320494454796981, logpriors=[-7.163277093525101], loglikes=array([11.48377155]), derived=[], finite=False)\n",
      "Last proposal: [-1.46534041  4.38626909]\n",
      "With rejected result: LogPosterior(logpost=-36.954552255918486, logpriors=[-5.718431825416216], loglikes=array([-31.23612043]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mcmc] *ERROR* The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-0.05150964, a1:5.346839\n",
      "Current result: LogPosterior(logpost=5.002668958435729, logpriors=[-5.818497948569215], loglikes=array([10.82116691]), derived=[], finite=False)\n",
      "Last proposal: [ 8.36402549 22.51992059]\n",
      "With rejected result: LogPosterior(logpost=-44.238954042017546, logpriors=[-13.436725811255718], loglikes=array([-30.80222823]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-72:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 133, in queue_chains\n",
      "    KL = run_chains(nre,info_this,is_nre)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_554141/1916989724.py\", line 55, in run_chains\n",
      "    updated_info_nre, sampler_nre = run(info_nre)\n",
      "                                    ^^^^^^^^^^^^^\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/run.py\", line 143, in run\n",
      "    sampler.run()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 387, in run\n",
      "    self.get_new_sample()\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 466, in get_new_sample_metropolis\n",
      "    self.process_accept_or_reject(accept, trial, trial_results)\n",
      "  File \"/home/aseem/anaconda3/lib/python3.11/site-packages/cobaya/samplers/mcmc/mcmc.py\", line 608, in process_accept_or_reject\n",
      "    raise LoggedError(\n",
      "cobaya.log.LoggedError: The chain has been stuck for 1000 attempts, stopping sampling. Make sure the reference point is sensible and initial covmat. For parameters not included in an initial covmat, the 'proposal' width set for each parameter should be of order of the expected conditional posterior width, which may be much smaller than the marginalized posterior width - choose a smaller rather than larger value if in doubt. You can also decrease the 'proposal_scale' option for mcmc, though small values will sample less efficiently once things converge. Or make your starting 'ref'tighter around an expected best-fit value\n",
      "Alternatively (though not advisable) make 'max_tries: np.inf' (or 'max_tries: .inf' in yaml).\n",
      "Current point: a0:-0.05150964, a1:5.346839\n",
      "Current result: LogPosterior(logpost=5.002668958435729, logpriors=[-5.818497948569215], loglikes=array([10.82116691]), derived=[], finite=False)\n",
      "Last proposal: [ 8.36402549 22.51992059]\n",
      "With rejected result: LogPosterior(logpost=-44.238954042017546, logpriors=[-13.436725811255718], loglikes=array([-30.80222823]), derived=[], finite=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... cleanup\n",
      "55 min 22.30 seconds\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_554141/1916989724.py:145: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  KLvals[r] = KLDict[r+1]#['KL']\n"
     ]
    }
   ],
   "source": [
    "N_repeat = 50\n",
    "NProc = np.min([4,N_repeat]) \n",
    "\n",
    "print('Architecture:'+nre.file_stem+' ...')\n",
    "\n",
    "Like_Dir = '../code/likes/'\n",
    "\n",
    "Max_Samples = 1000000\n",
    "Rminus1_Stop = 0.01 # 0.005\n",
    "Rminus1_CL_Stop = 0.025 # 0.025\n",
    "Rminus1_CL_Level = 0.95 # 95\n",
    "\n",
    "Burn_In = 0\n",
    "Burn_Frac = 0.3 # for later use\n",
    "\n",
    "Latex_List = ['a_{{{0:d}}}'.format(p) for p in range(nre.nparam)]\n",
    "Params_List = ['a{0:d}'.format(p) for p in range(nre.nparam)]\n",
    "\n",
    "# Nd_ln_2pi = nre.ndata*np.log(2*np.pi)\n",
    "# Cinv,detC = nre.svd_inv(nre.cov_mat)\n",
    "# ln_det_Cd = np.log(detC)\n",
    "# constant = -0.5*(Nd_ln_2pi + ln_det_Cd) \n",
    "\n",
    "\n",
    "info_nre = {}\n",
    "info_nre['params'] = {}\n",
    "\n",
    "info_nre['likelihood'] = {'likelihoods.NRELike':\n",
    "                          {'python_path':Like_Dir}}\n",
    "\n",
    "for p in range(len(Params_List)):\n",
    "    ref = 0.0\n",
    "    info_nre['params'][Params_List[p]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "                                          'prior':{'dist':'norm','loc':nre.prior_mean[p],'scale':nre.prior_std[p]},\n",
    "                                          'proposal':0.01,'latex':Latex_List[p]}\n",
    "\n",
    "info_nre['sampler'] = {'mcmc':\n",
    "                       {'learn_proposal': True,\n",
    "                        'Rminus1_single_split': 4,\n",
    "                        'measure_speeds': True,\n",
    "                        'max_samples': Max_Samples,\n",
    "                        'max_tries': 1000,\n",
    "                        'Rminus1_stop': Rminus1_Stop,\n",
    "                        'Rminus1_cl_stop': Rminus1_CL_Stop,\n",
    "                        'Rminus1_cl_level': Rminus1_CL_Level,\n",
    "                        'burn_in': Burn_In}}\n",
    "info_output = File_Stem + '/stats/chains/'\n",
    "chain_plot_path = info_output+'/for_plots'\n",
    "Path(chain_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "info_nre[\"force\"] = True    \n",
    "info_nre[\"debug\"] = 40 # 40 = only error output generated (https://docs.python.org/2/library/logging.html#logging-levels)\n",
    "\n",
    "def run_chains(nre,info_nre,is_nre):\n",
    "    updated_info_nre, sampler_nre = run(info_nre)\n",
    "        \n",
    "    # Load chains\n",
    "    input_path = str(Path(info_nre[\"output\"]).resolve()) # note info_nre\n",
    "    gd_sample = loadMCSamples(input_path,settings={'ignore_rows':Burn_Frac})\n",
    "    sample = gd_sample.samples.T\n",
    "    \n",
    "    # Subsample chains\n",
    "    N_Boot = np.min([10000,int(0.2*sample[0].size)])\n",
    "    Ind = gd_sample.random_single_samples_indices(random_state=42,max_samples=N_Boot)\n",
    "    N_Boot = Ind.size\n",
    "    \n",
    "    # KL divergence D_{KL}(post_NRE || post_MCMC)\n",
    "    data_this = (info_nre['theory']['likelihoods.NRETheory']['data'] \n",
    "                 if is_nre else \n",
    "                 info_nre['likelihood']['likelihoods.Chi2Like']['Y'].T)\n",
    "    KL = 0.0\n",
    "    for b in range(N_Boot):\n",
    "        # lnPrior_b = -sample[-4,Ind[b]]\n",
    "        theta_b = nre.cv(sample[:nre.nparam,Ind[b]])\n",
    "        ratio,F,theta_hat = analytical_nre(nre,data_this,theta_b)\n",
    "        ratio_NRE = nre.predict(data_this,theta_b)\n",
    "        KL += np.log((ratio_NRE+1e-30)/(ratio+1e-30))\n",
    "        # lnPostNRE_b = np.log(nre.predict(data_this,theta_b)) + lnPrior_b\n",
    "        # # chi2_b = sample[-2,Ind[b]]\n",
    "        # # lnPostMCMC_b = -0.5*chi2_b + lnPrior_b + constant\n",
    "        # lnPostMCMC_b = np.log(ratio) + lnPrior_b\n",
    "        # KL += lnPostMCMC_b - lnPostNRE_b\n",
    "    KL /= (N_Boot*np.log(2))\n",
    "    return KL\n",
    "\n",
    "Tasks = []\n",
    "print('... setting up tasks')\n",
    "for r in range(N_repeat):\n",
    "    theta_test_this = nre.prior(1)\n",
    "    data_test_this = nre.simulator(theta_test_this)\n",
    "\n",
    "    info_nre_r = copy.deepcopy(info_nre)\n",
    "    nre_r = copy.deepcopy(nre)\n",
    "    \n",
    "    info_nre_r['output'] = info_output + 'nre_C{0:d}_r{1:d}'.format(Complexity,r+1)    \n",
    "    info_nre_r['theory'] = {'likelihoods.NRETheory':\n",
    "                            {'python_path':Like_Dir,'nre':nre_r,\n",
    "                             'data':data_test_this,\n",
    "                             'keys':Params_List}}\n",
    "    \n",
    "    if r == 0:\n",
    "        Tasks.append((nre_r,info_nre_r,False,run_chains))\n",
    "    Tasks.append((nre_r,info_nre_r,True,run_chains))\n",
    "\n",
    "    del nre_r,info_nre_r\n",
    "    gc.collect()\n",
    "    \n",
    "    nre.status_bar(r,N_repeat)\n",
    "\n",
    "def queue_chains(r,nre,info_nre,is_nre,run_chains,mdict):\n",
    "    # p = psutil.Process()\n",
    "    # p.cpu_affinity([n])\n",
    "    if not is_nre:\n",
    "        info_this = copy.deepcopy(info_nre)\n",
    "        data_this = info_this['theory']['likelihoods.NRETheory']['data'].copy()\n",
    "        info_this['output'] = info_output + 'mcmc_C{0:d}_r{1:d}'.format(Complexity,r+1)\n",
    "        info_this['likelihood'] = {'likelihoods.Chi2Like':\n",
    "                                  {'python_path':Like_Dir,\n",
    "                                   'X':nre.rv(nre.xvals),'Y':data_this.T,\n",
    "                                   'cov_mat':nre.cov_mat}}\n",
    "        if nre.file_stem[:8] == 'gaussmix':\n",
    "            info_this['theory'] = {'examplelikes.GaussMixTheory':\n",
    "                                  {'python_path':Like_Dir,\n",
    "                                   'X':nre.rv(nre.xvals),'ncomp':nre.ncomp}}\n",
    "        else:\n",
    "            info_this['theory'] = {'examplelikes.PolyTheory':\n",
    "                                  {'python_path':Like_Dir,\n",
    "                                   'X':nre.rv(nre.xvals)}}\n",
    "        del data_this\n",
    "        gc.collect()\n",
    "    else:\n",
    "        info_this = info_nre\n",
    "    KL = run_chains(nre,info_this,is_nre)\n",
    "    mdict[r+1] = KL\n",
    "    # mdict[r+1] = {'KL':KL,'data':info_nre['likelihoods.NRETheory']['data']}\n",
    "    return\n",
    "\n",
    "# from queuer import queue_chains\n",
    "\n",
    "KLvals = np.zeros(N_repeat)\n",
    "# Data = np.zeros((N_repeat,nre.ndata,1))\n",
    "start_time = time()\n",
    "KLDict = nre.run_processes(Tasks,queue_chains,NProc)\n",
    "for r in range(N_repeat):\n",
    "    KLvals[r] = KLDict[r+1]#['KL']\n",
    "    # Data[r] = KLDict[r+1]['data']\n",
    "    \n",
    "print('... cleanup')\n",
    "\n",
    "files = [f for f in Path().glob(info_output+'mcmc_C{0:d}_r1.*'.format(Complexity))]\n",
    "for f in files:\n",
    "    shutil.copy(f,chain_plot_path)\n",
    "\n",
    "files = [f for f in Path().glob(info_output+'nre_C{0:d}_r1.*'.format(Complexity))]\n",
    "for f in files:\n",
    "    shutil.copy(f,chain_plot_path)\n",
    "\n",
    "files = [f for f in Path().glob(info_output+'mcmc_C*.*')]\n",
    "for f in files:\n",
    "    Path.unlink(f)\n",
    "\n",
    "files = [f for f in Path().glob(info_output+'nre_C*.*')]\n",
    "for f in files:\n",
    "    Path.unlink(f)\n",
    "\n",
    "del Tasks\n",
    "gc.collect()\n",
    "\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a1534a1-736c-468d-836d-8e0fba2b1f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used 24 of 50 measured values\n",
      "KL + lg(evidence) = 2.1708 +- 3.8869\n",
      "\n",
      "Reading architecture data from: poly_avg20/archs.pkl\n",
      "Storing architecture data to: poly_avg20/archs.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{320445801: {'KL': 11.419661887782768,\n",
       "  'KL84': 27.326055065189088,\n",
       "  'KL16': 4.340893563498894,\n",
       "  'KLstd': 11.492580750845097,\n",
       "  'Nwts': 17901},\n",
       " 4329771601: {'KL': 2.2753288080708955,\n",
       "  'KL84': 5.67818265052968,\n",
       "  'KL16': 0.04846671435284473,\n",
       "  'KLstd': 2.814857968088418,\n",
       "  'Nwts': 65801},\n",
       " 34114459401: {'KL': 2.170787259145476,\n",
       "  'KL84': 8.379207067520316,\n",
       "  'KL16': 0.6054438142877038,\n",
       "  'KLstd': 3.8868816266163058,\n",
       "  'Nwts': 184701}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_finite = np.where(np.isfinite(KLvals))[0]\n",
    "KL = np.median(KLvals[ind_finite])\n",
    "KL84 = np.percentile(KLvals[ind_finite],84)\n",
    "KL16 = np.percentile(KLvals[ind_finite],16)\n",
    "KLstd = 0.5*(KL84 - KL16)\n",
    "print('Used {0:d} of {1:d} measured values'.format(ind_finite.size,KLvals.size))\n",
    "print('KL + lg(evidence) = {0:.4f} +- {1:.4f}\\n'.format(KL,KLstd))\n",
    "\n",
    "First_Arch = False\n",
    "\n",
    "Arch_File = File_Stem + '/archs.pkl'\n",
    "if First_Arch:\n",
    "    archs = {Complexity:{'KL':KL,'KL84':KL84,'KL16':KL16,'KLstd':KLstd,'Nwts':nre.net[1].calc_N_freeparams()}}\n",
    "else:\n",
    "    print('Reading architecture data from:',Arch_File)\n",
    "    with open(Arch_File, 'rb') as f:\n",
    "        archs = pickle.load(f)  \n",
    "    archs[Complexity] = {'KL':KL,'KL84':KL84,'KL16':KL16,'KLstd':KLstd,'Nwts':nre.net[1].calc_N_freeparams()}\n",
    "\n",
    "print('Storing architecture data to:',Arch_File)\n",
    "with open(Arch_File, 'wb') as f:\n",
    "    pickle.dump(archs,f)  \n",
    "archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee3a56bd-67eb-4777-85d9-c19c11851523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arch_File = File_Stem + '/archs.pkl'\n",
    "# with open(Arch_File, 'rb') as f:\n",
    "#     archs = pickle.load(f)  \n",
    "# archs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93fd1538-9ac3-4727-9d8f-830b7092e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Arch_File = File_Stem + '/archs.pkl'\n",
    "with open(Arch_File, 'rb') as f:\n",
    "    archs = pickle.load(f)  \n",
    "Complexities = list(archs.keys())#[:-1] \n",
    "N_Archs = len(Complexities)\n",
    "# storage for median,+error,-error,complexity,Nfree,Ntrain/Nfree\n",
    "KLstats = np.zeros(N_Archs,dtype=[('KL',float),('KL+',float),('KL-',float),\n",
    "                                  ('complexity',int),('Nwts',int),('freedom',float)]) \n",
    "for a in range(N_Archs):\n",
    "    complexity = Complexities[a]\n",
    "    KLstats['KL'][a] = archs[complexity]['KL']\n",
    "    KLstats['KL+'][a] = archs[complexity]['KL84'] - archs[complexity]['KL']\n",
    "    KLstats['KL-'][a] = archs[complexity]['KL'] - archs[complexity]['KL16']\n",
    "    KLstats['complexity'][a] = complexity\n",
    "    KLstats['Nwts'][a] = archs[complexity]['Nwts']\n",
    "    KLstats['freedom'][a] = (1-ValFrac)*complexity/archs[complexity]['Nwts']**2\n",
    "\n",
    "KLstats = np.sort(KLstats,order='complexity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8ae2a-779f-4cae-a5c4-1f5b6ea91f32",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eaf0ef72-018e-4f4c-8cce-24c0c11e78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Save_Fig = True\n",
    "\n",
    "Show_MCMC = True\n",
    "Show_NRE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "307441d5-2b8b-4c33-b846-fe4874bbb4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.xlim(2e4,2e11)\n",
    "plt.ylim(8e-2,2e2)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "eps = 1e-1\n",
    "# c8941 = (KLstats['Nwts'] == 8941)\n",
    "cfree = (KLstats['freedom'] > 1+eps) #& ~c8941\n",
    "plt.errorbar(KLstats['complexity'][cfree],\n",
    "             KLstats['KL'][cfree],\n",
    "             yerr=np.array([KLstats['KL-'][cfree],KLstats['KL+'][cfree]]),\n",
    "             c='crimson',marker='o',capsize=5,label='free',lw=1)\n",
    "cmarg = (np.fabs(KLstats['freedom'] - 1.0) <= eps) #& ~c8941\n",
    "plt.errorbar(KLstats['complexity'][cmarg],\n",
    "             KLstats['KL'][cmarg],\n",
    "             yerr=np.array([KLstats['KL-'][cmarg],KLstats['KL+'][cmarg]]),\n",
    "             c='indigo',marker='o',capsize=5,label='marginal',lw=1)\n",
    "ccons = (KLstats['freedom'] < 1-eps) #& ~c8941\n",
    "plt.errorbar(KLstats['complexity'][ccons],\n",
    "             KLstats['KL'][ccons],\n",
    "             yerr=np.array([KLstats['KL-'][ccons],KLstats['KL+'][ccons]]),\n",
    "             c='gray',marker='o',capsize=5,label='constrained',lw=1)\n",
    "# plt.errorbar(KLstats['complexity'][c8941],\n",
    "#              KLstats['KL'][c8941],\n",
    "#              yerr=np.array([KLstats['KL-'][c8941],KLstats['KL+'][c8941]]),\n",
    "#              c='k',marker='o',capsize=5,label='Nwts = 8941',lw=1,alpha=0.1)\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa2de5-2b86-417d-835f-4a5fb4413028",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf1cf98-a79e-4f53-921a-84586c923c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCMC...\n",
      "... best fit ( a0,...a1) = ( -1.6781e+00,3.7795e+00 )\n",
      "... std dev  ( a0,...a1) = ( 5.7176e-02,4.3966e-02 )\n",
      "... chi2_best,dof,chi2_red,pval: 11.824,13,0.910,6.446e-01\n",
      "NN...\n",
      "... best fit ( a0,...a1) = ( -1.6606e+00,3.7795e+00 )\n",
      "... std dev  ( a0,...a1) = ( 5.9224e-02,4.3010e-02 )\n",
      "... chi2_best,dof,chi2_red,pval: -20.670,13,-1.590,nan\n",
      "Writing to file: poly_avg20/plots/contours_poly_avg20_C34114459401.png\n",
      "0 min 0.39 seconds\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 320x320 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "n_params = len(nre.prior_mean)\n",
    "dim = 1*n_params\n",
    "dof = ndata - n_params\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "# gd_sample = sampler.products(to_getdist=True)[\"sample\"]\n",
    "\n",
    "if Show_MCMC:\n",
    "    gd_sample = loadMCSamples(str(Path(chain_plot_path+'/mcmc_C{0:d}_r1'.format(Complexity)).resolve()),\n",
    "                                  settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample.label = 'MCMC' \n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat = gd_sample.getCovMat().matrix[:dim, :dim]\n",
    "    sample = gd_sample.samples\n",
    "    sample = sample.T\n",
    "    ibest = sample[-2].argmin()\n",
    "    mcmc_best = sample[:dim,ibest]\n",
    "    mcmc_chi2 = sample[-2,ibest]\n",
    "    pval = sysp.gammainc(mcmc_chi2/2,dof/2)\n",
    "    mcmc_sig = np.sqrt(np.diag(mcmc_covmat))\n",
    "    print('MCMC...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_best])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2,dof,mcmc_chi2/dof,pval))\n",
    "\n",
    "if Show_NRE:\n",
    "    gd_sample_nre = loadMCSamples(str(Path(chain_plot_path+'/nre_C{0:d}_r1'.format(Complexity)).resolve()),\n",
    "                                  settings={'ignore_rows':Burn_Frac})\n",
    "    gd_sample_nre.label = 'NRE: C{0:d}'.format(Complexity)\n",
    "    # samples contain params | chi2 | chi2__name | ?? | ??\n",
    "    mcmc_covmat_nre = gd_sample_nre.getCovMat().matrix[:dim, :dim]\n",
    "    sample_nre = gd_sample_nre.samples\n",
    "    sample_nre = sample_nre.T\n",
    "    iNRE_Id = sample_nre[-2].argmin()\n",
    "    mcmc_NRE_Id = sample_nre[:dim,iNRE_Id]\n",
    "    mcmc_chi2_nre = sample_nre[-2,iNRE_Id]\n",
    "    pval_nre = sysp.gammainc(mcmc_chi2_nre/2,dof/2)\n",
    "    mcmc_sig_nre = np.sqrt(np.diag(mcmc_covmat_nre))\n",
    "    print('NN...')\n",
    "    print(\"... best fit ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_NRE_Id])+\" )\")\n",
    "    print(\"... std dev  ( a0,...a{0:d}) = ( \".format(n_params-1)+','.join(['%.4e' % (pval,) for pval in mcmc_sig_nre])+\" )\")\n",
    "    print(\"... chi2_best,dof,chi2_red,pval: {0:.3f},{1:d},{2:.3f},{3:.3e}\".format(mcmc_chi2_nre,dof,mcmc_chi2_nre/dof,pval_nre))\n",
    "\n",
    "plot_param_list = Params_List\n",
    "Subplot_Size = 1.6\n",
    "\n",
    "gdplot = gdplt.get_subplot_plotter(subplot_size=Subplot_Size)\n",
    "gdplot.settings.num_plot_contours = 3\n",
    "gdplot.settings.axes_fontsize = FS3\n",
    "gdplot.settings.axes_labelsize = FS2\n",
    "gdplot.settings.title_limit_fontsize = FS3\n",
    "\n",
    "show_list = []\n",
    "fill_list = []\n",
    "col_list = []\n",
    "if Show_MCMC:\n",
    "    show_list.append(gd_sample)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('indigo')\n",
    "if Show_NRE:\n",
    "    show_list.append(gd_sample_nre)\n",
    "    fill_list.append(True)\n",
    "    col_list.append('crimson')\n",
    "gdplot.triangle_plot(show_list, plot_param_list,filled=fill_list,\n",
    "                     contour_colors=col_list,legend_loc='upper right',\n",
    "                     title_limit=0)\n",
    "for par_y in range(dim):\n",
    "    str_y = plot_param_list[par_y]\n",
    "    ax = gdplot.subplots[par_y,par_y]\n",
    "    if Show_MCMC:\n",
    "        ax.axvline(mcmc_best[par_y],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "    if Show_NRE:\n",
    "        ax.axvline(mcmc_NRE_Id[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "    for par_x in range(par_y):\n",
    "        str_x = plot_param_list[par_x]\n",
    "        ax = gdplot.subplots[par_y,par_x]\n",
    "        if Show_MCMC:\n",
    "            ax.scatter([mcmc_best[par_x]],[mcmc_best[par_y]],marker='*',s=50,c='aliceblue')\n",
    "            ax.axvline(mcmc_best[par_x],c='indigo',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_best[par_y],c='indigo',ls='--',lw=1.5,alpha=0.6)\n",
    "        if Show_NRE:\n",
    "            ax.scatter([mcmc_NRE_Id[par_x]],[mcmc_NRE_Id[par_y]],marker='*',s=50,c='peachpuff')\n",
    "            ax.axvline(mcmc_NRE_Id[par_x],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "            ax.axhline(mcmc_NRE_Id[par_y],c='crimson',ls='--',lw=1,alpha=0.6)\n",
    "\n",
    "if Save_Fig:\n",
    "    filename = 'contours_'+File_Stem+'_C{0:d}.png'.format(Complexity)\n",
    "    print('Writing to file: '+Plots_Dir+filename)\n",
    "    gdplot.export(fname=filename,adir=Plots_Dir)\n",
    "\n",
    "nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e43faf3a-a321-48d4-a3f0-a6800a168f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_repeat = 50\n",
    "# NProc = np.min([4,N_repeat]) \n",
    "\n",
    "# print('Architecture:'+nre.file_stem+' ...')\n",
    "\n",
    "# Like_Dir = '../code/likes/'\n",
    "\n",
    "# Run_MCMC = True\n",
    "# Run_NRE = True\n",
    "\n",
    "# Max_Samples = 1000000\n",
    "# Rminus1_Stop = 0.01 # 0.005\n",
    "# Rminus1_CL_Stop = 0.05 # 0.025\n",
    "# Rminus1_CL_Level = 0.95 # 95\n",
    "\n",
    "# Burn_In = 0\n",
    "# Burn_Frac = 0.3 # for later use\n",
    "\n",
    "# Latex_List = ['a_{{{0:d}}}'.format(p) for p in range(nre.nparam)]\n",
    "# Params_List = ['a{0:d}'.format(p) for p in range(nre.nparam)]\n",
    "\n",
    "# # Nd_ln_2pi = nre.ndata*np.log(2*np.pi)\n",
    "# # Cinv,detC = nre.svd_inv(nre.cov_mat)\n",
    "# # ln_det_Cd = np.log(detC)\n",
    "# # constant = -0.5*(Nd_ln_2pi + ln_det_Cd) \n",
    "\n",
    "\n",
    "# info = {}\n",
    "# info['params'] = {}\n",
    "\n",
    "# if nre.file_stem[:8] == 'gaussmix':\n",
    "#     info['theory'] = {'examplelikes.GaussMixTheory':\n",
    "#                       {'python_path':Like_Dir,\n",
    "#                        'X':nre.rv(nre.xvals),'ncomp':nre.ncomp}}\n",
    "# else:\n",
    "#     info['theory'] = {'examplelikes.PolyTheory':\n",
    "#                       {'python_path':Like_Dir,\n",
    "#                        'X':nre.rv(nre.xvals)}}\n",
    "# for p in range(len(Params_List)):\n",
    "#     ref = 0.0\n",
    "#     info['params'][Params_List[p]] = {'ref':{'min':ref-0.001,'max':ref+0.001},\n",
    "#                                       'prior':{'dist':'norm','loc':nre.prior_mean[p],'scale':nre.prior_std[p]},\n",
    "#                                       'proposal':0.01,'latex':Latex_List[p]}\n",
    "\n",
    "# info['sampler'] = {'mcmc':\n",
    "#                    {'learn_proposal': True,\n",
    "#                     'Rminus1_single_split': 4,\n",
    "#                     'measure_speeds': True,\n",
    "#                     'max_samples': Max_Samples,\n",
    "#                     'max_tries': 1000,\n",
    "#                     'Rminus1_stop': Rminus1_Stop,\n",
    "#                     'Rminus1_cl_stop': Rminus1_CL_Stop,\n",
    "#                     'Rminus1_cl_level': Rminus1_CL_Level,\n",
    "#                     'burn_in': Burn_In}}\n",
    "# info_output = File_Stem + '/stats/chains/'\n",
    "# chain_plot_path = info_output+'/for_plots'\n",
    "# Path(chain_plot_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# info[\"force\"] = True    \n",
    "# info[\"debug\"] = 40 # 40 = only error output generated (https://docs.python.org/2/library/logging.html#logging-levels)\n",
    "\n",
    "# info_nre = copy.deepcopy(info)\n",
    "# info_nre['likelihood'] = {'likelihoods.NRELike':\n",
    "#                          {'python_path':Like_Dir}}\n",
    "\n",
    "# Tasks = []\n",
    "# print('... setting up tasks')\n",
    "# for r in range(N_repeat):\n",
    "#     theta_test_this = nre.prior(1)\n",
    "#     data_test_this = nre.simulator(theta_test_this)\n",
    "\n",
    "#     info_r = copy.deepcopy(info)\n",
    "#     info_nre_r = copy.deepcopy(info_nre)\n",
    "#     nre_r = copy.deepcopy(nre)\n",
    "    \n",
    "#     info_r['output'] = info_output + 'mcmc_C{0:d}_r{1:d}'.format(Complexity,r+1)\n",
    "#     info_nre_r['output'] = info_output + 'nre_C{0:d}_r{1:d}'.format(Complexity,r+1)    \n",
    "#     info_r['likelihood'] = {'likelihoods.Chi2Like':\n",
    "#                           {'python_path':Like_Dir,\n",
    "#                            'X':nre.rv(nre.xvals),'Y':data_test_this.T,'cov_mat':nre.cov_mat}}\n",
    "    \n",
    "#     info_nre_r['theory'] = {'likelihoods.NRETheory':\n",
    "#                              {'python_path':Like_Dir,\n",
    "#                               'nre':nre_r,'data':data_test_this,'keys':Params_List}}\n",
    "#     run_mcmc = Run_MCMC if r==0 else False\n",
    "#     Tasks.append((nre_r,info_r,info_nre_r,run_mcmc,run_chains))\n",
    "\n",
    "#     del nre_r,info_r,info_nre_r\n",
    "#     gc.collect()\n",
    "    \n",
    "#     nre.status_bar(r,N_repeat)\n",
    "\n",
    "# def queue_chains(r,nre,info,info_nre,run_mcmc,run_chains,mdict):\n",
    "#     # p = psutil.Process()\n",
    "#     # p.cpu_affinity([n])\n",
    "#     KL = run_chains(nre,info,info_nre,run_mcmc)\n",
    "#     mdict[r+1] = KL\n",
    "#     # mdict[r+1] = {'KL':KL,'data':info_nre['likelihoods.NRETheory']['data']}\n",
    "#     return\n",
    "\n",
    "\n",
    "# def run_chains(nre,info,info_nre,run_mcmc):\n",
    "#     # Run chains\n",
    "#     if run_mcmc:\n",
    "#     # if Run_MCMC:\n",
    "#         updated_info, sampler = run(info)\n",
    "#     # else:\n",
    "#     #     print('Chains (hopefully) exist!')\n",
    "    \n",
    "#     if Run_NRE:\n",
    "#         updated_info_nre, sampler_nre = run(info_nre)\n",
    "#     # else:\n",
    "#     #     print('Chains (hopefully) exist!')\n",
    "#     # Load chains\n",
    "#     # input_path = str(Path(info[\"output\"]).resolve())\n",
    "#     input_path = str(Path(info_nre[\"output\"]).resolve()) # note info_nre\n",
    "#     gd_sample = loadMCSamples(input_path,settings={'ignore_rows':Burn_Frac})\n",
    "#     sample = gd_sample.samples.T\n",
    "    \n",
    "#     # Subsample chains\n",
    "#     N_Boot = np.min([10000,int(0.2*sample[0].size)])\n",
    "#     Ind = gd_sample.random_single_samples_indices(random_state=42,max_samples=N_Boot)\n",
    "#     N_Boot = Ind.size\n",
    "    \n",
    "#     # KL divergence D_{KL}(post_NRE || post_MCMC)\n",
    "#     data_this = info_nre['theory']['likelihoods.NRETheory']['data']\n",
    "#     KL = 0.0\n",
    "#     for b in range(N_Boot):\n",
    "#         # lnPrior_b = -sample[-4,Ind[b]]\n",
    "#         theta_b = nre.cv(sample[:nre.nparam,Ind[b]])\n",
    "#         ratio,F,theta_hat = analytical_nre(nre,data_this,theta_b)\n",
    "#         ratio_NRE = nre.predict(data_this,theta_b)\n",
    "#         KL += np.log((ratio_NRE+1e-30)/(ratio+1e-30))\n",
    "#         # lnPostNRE_b = np.log(nre.predict(data_this,theta_b)) + lnPrior_b\n",
    "#         # # chi2_b = sample[-2,Ind[b]]\n",
    "#         # # lnPostMCMC_b = -0.5*chi2_b + lnPrior_b + constant\n",
    "#         # lnPostMCMC_b = np.log(ratio) + lnPrior_b\n",
    "#         # KL += lnPostMCMC_b - lnPostNRE_b\n",
    "#     KL /= (N_Boot*np.log(2))\n",
    "#     return KL\n",
    "\n",
    "# KLvals = np.zeros(N_repeat)\n",
    "# # Data = np.zeros((N_repeat,nre.ndata,1))\n",
    "# start_time = time()\n",
    "# KLDict = nre.run_processes(Tasks,queue_chains,NProc)\n",
    "# for r in range(N_repeat):\n",
    "#     KLvals[r] = KLDict[r+1]#['KL']\n",
    "#     # Data[r] = KLDict[r+1]['data']\n",
    "    \n",
    "# print('... cleanup')\n",
    "\n",
    "# if Run_MCMC:\n",
    "#     files = [f for f in Path().glob(info_output+'mcmc_C{0:d}_r1.*'.format(Complexity))]\n",
    "#     for f in files:\n",
    "#         shutil.copy(f,chain_plot_path)\n",
    "\n",
    "# if Run_NRE:\n",
    "#     files = [f for f in Path().glob(info_output+'nre_C{0:d}_r1.*'.format(Complexity))]\n",
    "#     for f in files:\n",
    "#         shutil.copy(f,chain_plot_path)\n",
    "\n",
    "# files = [f for f in Path().glob(info_output+'mcmc*.*')]\n",
    "# for f in files:\n",
    "#     Path.unlink(f)\n",
    "\n",
    "# files = [f for f in Path().glob(info_output+'nre_C*.*')]\n",
    "# for f in files:\n",
    "#     Path.unlink(f)\n",
    "\n",
    "# del Tasks\n",
    "# gc.collect()\n",
    "\n",
    "# nre.time_this(start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f0db68-53cd-4a42-9b4e-ad3f11eae06c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
